{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "James Gardner and S. Borhanian, 2022 \n",
    "#### based on quick_start.ipynb by Borhanian "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to analyse science case/s for CE only:\n",
    "\n",
    "CE-N 40km with CE-S 40km or 20km\n",
    "\n",
    "if done, then look at CE-S with one ET detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwbench import network\n",
    "from gwbench import wf_class as wfc\n",
    "from gwbench import detector_response_derivatives as drd\n",
    "from gwbench import injections\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "# from p_tqdm import p_map\n",
    "from p_tqdm import p_umap\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PI = np.pi\n",
    "\n",
    "class PassEnterExit:\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "\n",
    "# https://stackoverflow.com/a/45669280; use as ``with HiddenPrints():''\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        \n",
    "def generate_symbolic_derivatives(wf_model_name, wf_other_var_dic, deriv_symbs_string,\n",
    "                                locs, use_rot, output_path=None):\n",
    "    \"\"\"generate symbolic derivatives, from generate_lambdified_functions.py from S. Borhanian 2020\n",
    "    use network's wf_model_name, wf_other_var_dic, deriv_symbs_string, and use_rot\n",
    "    will print 'Done.' when finished unless all files already exist in which it will print as such\n",
    "    \n",
    "    # # how to print settings as a sanity check\n",
    "    # print('wf_model_name = \\'{}\\''.format(wf.wf_model_name))\n",
    "    # print('wf_other_var_dic = {}'.format(wf.wf_other_var_dic))\n",
    "    # print('deriv_symbs_string = \\'{}\\''.format(deriv_symbs_string))\n",
    "    # print('use_rot = %i'%use_rot)\"\"\"\n",
    "    # skip if derivatives already exist\n",
    "    file_names = ['par_deriv_WFM_'+wf_model_name+'_VAR_'+deriv_symbs_string.replace(' ', '_')+'_DET_'+key+'.dat' for key in locs]\n",
    "    file_names.append('par_deriv_WFM_'+wf_model_name+'_VAR_'+deriv_symbs_string.replace(' ra', '').replace(' dec', '').replace(' psi', '').replace(' ', '_')+'_DET_'+'pl_cr'+'.dat')\n",
    "    path = 'lambdified_functions/'\n",
    "    file_names_existing = [file_name for file_name in file_names if os.path.isfile(path+file_name)]\n",
    "    if len(file_names_existing) < len(file_names):\n",
    "        # if a file doesn't exist, generate them all again\n",
    "        # waveform\n",
    "        wf = wfc.Waveform(wf_model_name, wf_other_var_dic)\n",
    "        # lambidified detector reponses and derivatives\n",
    "        drd.generate_det_responses_derivs_sym(wf, deriv_symbs_string, locs=locs, use_rot=use_rot,\n",
    "                                              user_lambdified_functions_path=output_path)   \n",
    "    else:\n",
    "        print('All lambdified derivatives already exist.')\n",
    "        \n",
    "def basic_network_benchmarking(net, numerical_over_symbolic_derivs=True, only_net=True,\n",
    "                               numerical_deriv_settings=dict(step=1e-9, method='central', order=2, n=1),\n",
    "                               hide_prints=True):\n",
    "    \"\"\"computes network SNR, measurement errors, and sky area using gwbench FIM analysis\n",
    "    no return, saves results natively in network (net.snr, net.errs)\n",
    "    assumes that network is already set up, with waveform set etc.\"\"\"\n",
    "    if hide_prints:\n",
    "        entry_class = HiddenPrints\n",
    "    else:\n",
    "        entry_class = PassEnterExit\n",
    "    with entry_class():\n",
    "        # compute the WF polarizations and their derivatives\n",
    "        net.calc_wf_polarizations()\n",
    "        if numerical_over_symbolic_derivs:\n",
    "            # --- numerical differentiation ---\n",
    "            net.calc_wf_polarizations_derivs_num(**numerical_deriv_settings)\n",
    "        else:\n",
    "            # --- symbolic differentiation ---\n",
    "            net.load_wf_polarizations_derivs_sym()\n",
    "            net.calc_wf_polarizations_derivs_sym()\n",
    "\n",
    "        # setup antenna patterns, location phase factors, and PSDs\n",
    "        net.setup_ant_pat_lpf_psds()\n",
    "\n",
    "        # compute the detector responses and their derivatives\n",
    "        net.calc_det_responses()\n",
    "        if numerical_over_symbolic_derivs:       \n",
    "            # --- numerical differentiation ---\n",
    "            net.calc_det_responses_derivs_num(**numerical_deriv_settings)\n",
    "        else:\n",
    "            # --- symbolic differentiation ---\n",
    "            net.load_det_responses_derivs_sym()\n",
    "            net.calc_det_responses_derivs_sym()\n",
    "\n",
    "        # calculate the network and detector SNRs\n",
    "        net.calc_snrs(only_net=only_net)\n",
    "        # calculate the Fisher and covariance matrices, then error estimates\n",
    "        net.calc_errors(only_net=only_net) #cond_sup=# 1e15 (default) or None (allows all)\n",
    "        # calculate the 90%-credible sky area (in [deg]^2)\n",
    "        net.calc_sky_area_90(only_net=only_net)\n",
    "\n",
    "# https://note.nkmk.me/en/python-numpy-nan-remove/\n",
    "without_rows_w_nan = lambda xarr : xarr[np.logical_not(np.isnan(xarr)).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of simple benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following quick_start.ipynb as a guide \n",
    "# Network initialisation\n",
    "\n",
    "# initialisation is '<config>_<site>'\n",
    "# other configurations (Tab.4): aLIGO,A+,V+,K+,Voyager-CBO,Voyager-PMO,ET \n",
    "# CE configs: <stage>-<arm length>-<optimisation> = CE1/CE2-10/20/30/40-CBO/PMO\n",
    "# sites/locations (Tab.3): H,L,V,K,I,E,C,N,S; the latter three are Main, North, and South for CE\n",
    "\n",
    "# choose the desired detectors\n",
    "# CE-N 40km, CE-S 40km:\n",
    "# network_spec = ['CE1-40-CBO_C', 'CE1-40-CBO_S']\n",
    "# network_spec = ['CE2-40-CBO_C', 'CE2-40-CBO_S'] # 2nd stage of development, compare as well\n",
    "# # CE-N 40km, CE-S 20km:\n",
    "# network_spec = ['CE1-40-CBO_C', 'CE1-20-PMO_S']\n",
    "# network_spec = ['CE2-40-CBO_C', 'CE2-20-PMO_S'] # 2nd stage\n",
    "# locs = ['C', 'S']\n",
    "network_spec, locs = ['aLIGO_H', 'aLIGO_L', 'aLIGO_V'], ['H', 'L', 'V']\n",
    "\n",
    "# initialize the network with the desired detectors\n",
    "net = network.Network(network_spec)\n",
    "\n",
    "# frequency range\n",
    "f = np.arange(5., 61.5, 2**-4) # i.e. looking for CBCs around 50 Hz, change for PMO\n",
    "\n",
    "# choose the desired waveform \n",
    "wf_model_name = 'tf2' # TaylorF2, coded in gwbench, allows for symbolic differentiation\n",
    "wf_other_var_dic = None # for tf2 or tf2_tidal\n",
    "# other waveforms are available (e.g. tf2_tidal) but require different injection parameters\n",
    "\n",
    "# pass the chosen waveform to the network for initialization\n",
    "net.set_wf_vars(wf_model_name=wf_model_name)\n",
    "\n",
    "# injection parameters\n",
    "# for GW150914\n",
    "inj_params = {\n",
    "    'Mc':    30.9,\n",
    "    'eta':   0.247,\n",
    "    'chi1z': 0,\n",
    "    'chi2z': 0,\n",
    "    'DL':    475,\n",
    "    'tc':    0,\n",
    "    'phic':  0,\n",
    "    'iota':  PI/4,\n",
    "    'ra':    PI/4,\n",
    "    'dec':   PI/4,\n",
    "    'psi':   PI/4,\n",
    "    'gmst0': 0}\n",
    "\n",
    "# assign with respect to which parameters to take derivatives, for the FIM\n",
    "deriv_symbs_string = 'Mc eta DL tc phic iota ra dec psi'\n",
    "\n",
    "# assign which parameters to convert to cos or log versions\n",
    "conv_cos = ('iota', 'dec')\n",
    "conv_log = ('Mc', 'DL')\n",
    "\n",
    "# choose whether to take Earth's rotation into account\n",
    "use_rot = 0\n",
    "only_net = 1\n",
    "\n",
    "# pass all these variables to the network\n",
    "net.set_net_vars(\n",
    "    f=f, inj_params=inj_params,\n",
    "    deriv_symbs_string=deriv_symbs_string,\n",
    "    conv_cos=conv_cos, conv_log=conv_log,\n",
    "    use_rot=use_rot\n",
    "    )\n",
    "print('Network initialised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GW benchmarking\n",
    "# symbolic derivatives (faster)\n",
    "generate_symbolic_derivatives(wf_model_name, wf_other_var_dic, deriv_symbs_string, locs, use_rot)\n",
    "\n",
    "# compute the WF polarizations and their derivatives\n",
    "net.calc_wf_polarizations()\n",
    "# --- numerical differentiation ---\n",
    "# net.calc_wf_polarizations_derivs_num()\n",
    "# --- symbolic differentiation ---\n",
    "net.load_wf_polarizations_derivs_sym()\n",
    "net.calc_wf_polarizations_derivs_sym()\n",
    "\n",
    "# setup antenna patterns, location phase factors, and PSDs\n",
    "net.setup_ant_pat_lpf_psds()\n",
    "# results are accessed like this\n",
    "# net.detectors[0].Fp # [i] for ith detector in network\n",
    "# net.detectors[0].Fc # --> not frequency dependent?\n",
    "# net.detectors[0].Flp\n",
    "# net.detectors[0].psd # f in future calculations truncated to match psd\n",
    "\n",
    "# compute the detector responses and their derivatives\n",
    "# analogous to WF calculation\n",
    "net.calc_det_responses()\n",
    "# --- numerical differentiation ---\n",
    "# net.calc_det_responses_derivs_num()\n",
    "# --- symbolic differentiation ---\n",
    "net.load_det_responses_derivs_sym()\n",
    "net.calc_det_responses_derivs_sym()\n",
    "\n",
    "# access results (either way) via\n",
    "# net.detectors[0].hf\n",
    "# net.detectors[0].del_hf\n",
    "\n",
    "# calculate the network and detector SNRs\n",
    "net.calc_snrs(only_net=only_net)\n",
    "# print(net.snr, net.snr_sq, net.detectors[0].snr, net.detectors[0].snr_sq)\n",
    "\n",
    "# calculate the network and detector Fisher matrices, condition numbers, ...\n",
    "# ... covariance matrices, error estimates, and inversion errors\n",
    "net.calc_errors(only_net=only_net) # finds FIMs, then inverts to find covariance matrix and error estimates of params\n",
    "# print(net.fisher, net.cond_num, net.cov, net.errs, net.inv_err)\n",
    "# print(net.detectors[0].fisher, net.detectors[0].cond_num, net.detectors[0].cov,\n",
    "#       net.detectors[0].errs, net.detectors[0].inv_err)\n",
    "\n",
    "# calculate the 90%-credible sky area (in [deg]^2)\n",
    "net.calc_sky_area_90(only_net=only_net)\n",
    "print('\\nBenchmarking complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the contents of the detector objects (inside the network)\n",
    "# net.print_detectors()\n",
    "# print the contents of the network objects\n",
    "net.print_network()\n",
    "\n",
    "# net.get_snrs_errs_cov_fisher_inv_err_for_key(key='network')\n",
    "\n",
    "# # check if f truncated in any of the detectors to fit the psd\n",
    "# for i in range(len(net.detectors)):\n",
    "#     print(np.all(net.f == net.detectors[i].f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicating Fig 3 from Borhanian 2021 to test understanding, then try for CE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for GW170817 and tf2_tidal\n",
    "\n",
    "# select network\n",
    "net, locs = network.Network(['aLIGO_H','aLIGO_L','aLIGO_V']), ['H', 'L', 'V']\n",
    "# net, locs = network.Network(['CE1-40-CBO_C', 'CE1-40-CBO_S']), ['C', 'S']\n",
    "# to-do: for CE only, the FIM is ill-conditioned, how to fix this?\n",
    "\n",
    "# not stated, using one from GW170817 paper\n",
    "# start with 100 sample points, then move up from there (e.g. to 1e4)\n",
    "fmin, fmax, fnum = 30, 2048, 100\n",
    "f = np.linspace(fmin, fmax, fnum)\n",
    "\n",
    "wf_model_name = 'tf2_tidal'\n",
    "wf_other_var_dic = None\n",
    "net.set_wf_vars(wf_model_name=wf_model_name)\n",
    "\n",
    "# injection parameters for GW170817, reported median values (source-frame)\n",
    "# using low-spin priors (Borhanian doesn't say which they used)\n",
    "# https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.119.161101\n",
    "# subsequent work (2019) has refined these values\n",
    "base_measured_params = {\n",
    "    'Mc':    1.188, # Msun\n",
    "    'eta':   0.2485, # m1=1.48 Msun, m2=1.265 Msun, m2/m1=0.85, Mtot=2.74 Msun, eta=m1*m2/(m1+m2)**2\n",
    "    'chi1z': 0,\n",
    "    'chi2z': 0,\n",
    "    'DL':    40, # MPc\n",
    "    'tc':    0, # not quoted\n",
    "    'phic':  0,\n",
    "#     'iota':  PI/4, # 1000 random instances of these, measured: 55deg\n",
    "#     'ra':    PI/4, # 1000 random instances of these\n",
    "#     'dec':   PI/4, # 1000 random instances of these\n",
    "    'psi':   PI/4, # not quoted, to-do: check effect\n",
    "    'gmst0': 0, # not quoted but doesn't matter?\n",
    "    'lam_t': 800, # combined dimensionless tidal deformability\n",
    "    'delta_lam_t': 0 # not quoted, but approximating as zero because distributed around zero (check)\n",
    "}\n",
    "\n",
    "# assign with respect to which parameters to take derivatives, for the FIM, all 12 but not delta_lam_t (or gmst0)\n",
    "deriv_symbs_string = 'Mc eta chi1z chi2z DL tc phic iota ra dec psi lam_t'\n",
    "\n",
    "# assign which parameters to convert to log or cos versions for differentiation\n",
    "conv_log = ('Mc', 'DL', 'lam_t')\n",
    "conv_cos = ('iota', 'dec')\n",
    "\n",
    "# choose whether to take Earth's rotation into account\n",
    "use_rot = 0\n",
    "# whether to calculate snr, errors, sky area for just the network and not the individual detectors\n",
    "only_net = 1\n",
    "\n",
    "# create lambdified derivatives for speed\n",
    "generate_symbolic_derivatives(wf_model_name, wf_other_var_dic, deriv_symbs_string, locs, use_rot)\n",
    "\n",
    "# starting with just 10 instances, scale up to 1000 later\n",
    "num_instances = 1000 # 1000 is O(10 min) with numerical derivatives but is O(1 min) with symbolic derivatives\n",
    "file_tag = f'{num_instances}instances_{net.label}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles are sampled to avoid clumping at poles\n",
    "iota_ra_dec_randoms = np.transpose(injections.angle_sampler(num_instances, np.random.randint(100))[:-1])\n",
    "\n",
    "def calculate_snr_errs_skyarea(iota_ra_dec):\n",
    "    \"\"\"given an array of iota, ra, dec; return an array of the integrate snr, Mc and DL errors, and 90% sky area\"\"\"\n",
    "    iota, ra, dec = iota_ra_dec\n",
    "    inj_params = dict(**base_measured_params, iota=iota, ra=ra, dec=dec)\n",
    "\n",
    "    # copy network to avoid parallel operations conflicting, is this an issue when Pool() makes separate instances?\n",
    "    net_copy = deepcopy(net)\n",
    "\n",
    "    net_copy.set_net_vars(\n",
    "        f=f, inj_params=inj_params,\n",
    "        deriv_symbs_string=deriv_symbs_string,\n",
    "        conv_cos=conv_cos, conv_log=conv_log,\n",
    "        use_rot=use_rot\n",
    "    )\n",
    "\n",
    "    basic_network_benchmarking(net_copy, numerical_over_symbolic_derivs=False, only_net=only_net)\n",
    "\n",
    "    if net_copy.wc_fisher: # i.e. net.cond_num < 1e15:\n",
    "        # net_copy is automatically deleted once out of scope\n",
    "        return net_copy.snr, net_copy.errs['log_Mc'], net_copy.errs['log_DL'], net_copy.errs['sky_area_90']\n",
    "    else:\n",
    "        # try again with different random values\n",
    "        # to-do: add counter to quantify rate of occurance; seems to be v common with CE only, why?\n",
    "        #print(f'{net_copy.cond_num:.3g} is ill-conditioned, try again')\n",
    "        #return calculate_snr_errs_skyarea(np.transpose(injections.angle_sampler(1, np.random.randint(100))[:-1]))\n",
    "        # alternative to guarantee halting \n",
    "        return np.full(4, np.nan)\n",
    "\n",
    "# array to store integrated SNR, 1sigma error estimates (for Mc and DL), and 90% credible sky area\n",
    "# must be careful with parallelising that the network is not used simultaneously\n",
    "# keeping one cpu free to use laptop\n",
    "results_snr_errs_skyarea = np.array(p_umap(calculate_snr_errs_skyarea, iota_ra_dec_randoms, num_cpus=3))\n",
    "\n",
    "# save results\n",
    "np.save(f'data_snr_errs_skyarea/results_snr_errs_skyarea_{file_tag}.npy', results_snr_errs_skyarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load results\n",
    "results_snr_errs_skyarea = np.load(f'data_snr_errs_skyarea/results_snr_errs_skyarea_{file_tag}.npy')\n",
    "\n",
    "# filter out NaNs\n",
    "results_snr_errs_skyarea = without_rows_w_nan(results_snr_errs_skyarea)\n",
    "\n",
    "if len(results_snr_errs_skyarea) == 0:\n",
    "    print('All values are NaN, FIM is ill-conditioned.')\n",
    "else:\n",
    "    print('Some values are not NaN.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measured values\n",
    "# given Appendix E: Asymmetric Systematic Uncertainties, estimating the st.dev. from asymm errs depends on your model\n",
    "# in the Gaussian case, just average the upper and lower errors that correspond to 68% of the data\n",
    "# given a 90% credibility interval (x-xlower,x+xupper), the st.dev. is approximated by 1/1.64*1/2(xlower+xupper)\n",
    "meas_snr = 32.4\n",
    "# too high eyeballing wrt Borhanian 2021?\n",
    "meas_Mc_rel_err = 1/1.64*1/2*(0.004+0.002)/1.188 # 1.188+0.004-0.002, range for 90% credibility\n",
    "# too low eyeballing wrt Borhanian 2021?\n",
    "meas_LD_rel_err = 1/1.64*1/2*(8+14)/40 # 40+8âˆ’14\n",
    "meas_sky_area = 28\n",
    "meas_vals = meas_snr, meas_Mc_rel_err, meas_LD_rel_err, meas_sky_area\n",
    "\n",
    "# plotting\n",
    "# comparing symmetricised relative errors rather than 90% credible bounds\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, axs = plt.subplots(1, 4, figsize=(18, 2), sharey=True, gridspec_kw={'wspace':0.05, 'hspace':0})\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    data = results_snr_errs_skyarea[:,i]\n",
    "    ax.hist(data, histtype='step', facecolor='b', label='tf2_tidal',\n",
    "            bins=np.geomspace(data.min(), data.max(), 50))\n",
    "    ax.axvline(meas_vals[i], color='grey')\n",
    "    ax.set_xscale('log')\n",
    "    # NB: when there's no major tick, the axis has no reference value\n",
    "    ax.xaxis.set_minor_locator(plt.LogLocator(base=10.0, subs=0.1*np.arange(1, 10), numticks=10))\n",
    "    ax.xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "\n",
    "snr_xlim = axs[0].get_xlim()\n",
    "snr_threshold_lo = 10 # for detection\n",
    "snr_threshold_hi = 100 # for high fidelity\n",
    "for snr_threshold in snr_threshold_lo, snr_threshold_hi:\n",
    "    efficiency = np.mean(results_snr_errs_skyarea[:,0] > snr_threshold)\n",
    "    print(f\"efficiency of network is {efficiency:.1%} wrt SNR threshold {snr_threshold}\")\n",
    "axs[0].axvspan(snr_xlim[0], snr_threshold_lo, alpha=0.5, color='lightgrey')\n",
    "axs[0].axvspan(snr_xlim[0], snr_threshold_hi, alpha=0.25, color='lightgrey')\n",
    "axs[0].set_xlim(snr_xlim)\n",
    "\n",
    "axs[0].set_ylabel(r'GW170817')\n",
    "axs[0].set_xlabel(r'integrated SNR, $\\rho$')\n",
    "# error in log(X) is the fractional error in X (i.e. (error in X)/X) by chain rule \n",
    "axs[1].set_xlabel(r'chirp mass, $\\Delta\\mathcal{M}/\\mathcal{M}$')\n",
    "axs[2].set_xlabel(r'luminosity distance, $\\Delta D_L/D_L$')\n",
    "axs[3].set_xlabel(r'sky area, $\\Omega$ / $\\mathrm{deg}^2$')\n",
    "axs[0].legend()\n",
    "\n",
    "fig.align_labels()\n",
    "fig.savefig(f'GW170817_histograms_{file_tag}.pdf', bbox_inches='tight')\n",
    "plt.show(fig)\n",
    "plt.close(fig)\n",
    "# results for HLV disagree with Borhanian2021: sharpness of first twos' fall-offs, centre of snr distribution, measured Mc and DL, extent of sky area curve\n",
    "# however, with a difference 1000 instances, the results change --- so maybe just a sampling issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicating Borhanian and Sathya 2022 injections and detection rates, then for CE only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure: network, injection loop (inj, benchmark, save data), plot snr histogram, ...\n",
    "# ... calculate efficiency, calculate detection rate\n",
    "\n",
    "# try for this network, then CE only (refer to App E for CE discussion), compare to other five in Section 2a?\n",
    "# --- HLVKI+ ---\n",
    "network_spec = ['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I']\n",
    "locs = [x[-1] for x in network_spec]\n",
    "net = network.Network(network_spec)\n",
    "\n",
    "# --- BNS ---\n",
    "# waveform, LAL list: https://lscsoft.docs.ligo.org/lalsuite/lalsimulation/group___l_a_l_sim_inspiral__h.html\n",
    "wf_model_name = 'lal_bns'\n",
    "wf_other_var_dic = dict(approximant='IMRPhenomD_NRTidalv2') # for tidal, see https://arxiv.org/abs/1905.06011\n",
    "# to-do: fix \"TypeError: hfpc() missing 2 required positional arguments: 'lam_t' and 'delta_lam_t'\"\n",
    "# --> calculate tidal parameters from sampled m1, m2 in injections.py? requires Love number and radii (i.e. choose an EoS)\n",
    "# wf_model_name, wf_other_var_dic = 'tf2', None # to-do: stop using this once tidal params found\n",
    "net.set_wf_vars(wf_model_name=wf_model_name, wf_other_var_dic=wf_other_var_dic)\n",
    "# injection settings - source\n",
    "mass_dict = dict(dist='gaussian', mean=1.35, sigma=0.15, mmin=1, mmax=2)\n",
    "spin_dict = dict(geom='cartesian', dim=1, chi_lo=-0.05, chi_hi=0.05)\n",
    "# zmin, zmax, seed (use same seeds to replicate results)\n",
    "redshift_bins = ((0, 0.5, 7669), (0.5, 1, 3103), (1, 2, 4431), (2, 4, 5526), (4, 10, 7035), (10, 50, 2785))\n",
    "coeff_fisco = 4 # fmax = 4*fisco for BNS, 8*fisco for BBH\n",
    "\n",
    "base_params = {\n",
    "    'tc':    0,\n",
    "    'phic':  0,\n",
    "#     'gmst0': 0,\n",
    "    'lam_t': 800, # combined dimensionless tidal deformability, 800 for GW170817\n",
    "    'delta_lam_t': 0, # assuming zero but can be calculated if m1, m2, Love number, and EoS (i.e. radii) known\n",
    "}\n",
    "\n",
    "# derivative settings\n",
    "# assign with respect to which parameters to take derivatives for the FIM\n",
    "deriv_symbs_string = 'Mc eta DL tc phic iota ra dec psi'\n",
    "# assign which parameters to convert to log or cos versions for differentiation\n",
    "conv_cos = ('dec', 'iota')\n",
    "conv_log = ('Mc', 'DL', 'lam_t')\n",
    "numerical_deriv_settings = dict(step=1e-9, method='central', order=2, n=1) # default\n",
    "\n",
    "# network settings: whether to include Earth's rotation and individual detector calculations\n",
    "use_rot = 1\n",
    "only_net = 1\n",
    "\n",
    "# injection settings - other: number of injections per redshift bin (over 6 bins)\n",
    "num_injs = 10 # start with 10, then build to 1e6 (how did they compute 1e6 with numerical derivs?)\n",
    "redshifted = 1 # whether sample masses already redshifted wrt z\n",
    "if wf_other_var_dic is not None:\n",
    "    file_tag = f'NET_{net.label}_WF_{wf_model_name}_{wf_other_var_dic[\"approximant\"]}_NUM-INJS_{num_injs}'\n",
    "else:\n",
    "    file_tag = f'NET_{net.label}_WF_{wf_model_name}_NUM-INJS_{num_injs}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# injection and benchmarking\n",
    "# concatenate injection data from different bins\n",
    "inj_data = np.empty((len(redshift_bins)*num_injs, 14))\n",
    "for i, (zmin, zmax, seed) in enumerate(redshift_bins):\n",
    "    cosmo_dict = dict(sampler='uniform', zmin=zmin, zmax=zmax)\n",
    "    # transposed array to get [[Mc0, eta0, ..., z0], [Mc1, eta1, ..., z1], ...]\n",
    "    # [Mc, eta, chi1x, chi1y, chi1z, chi2x, chi2y, chi2z, DL, iota, ra, dec, psi, z]    \n",
    "    inj_data[i*num_injs:(i+1)*num_injs] = np.array(injections.injections_CBC_params_redshift(cosmo_dict, mass_dict, spin_dict, redshifted, num_injs=num_injs, seed=seed)).transpose()\n",
    "\n",
    "def calculate_benchmark_from_injection(inj):\n",
    "    \"\"\"given a 14-array of [Mc, eta, chi1x, chi1y, chi1z, chi2x, chi2y, chi2z, DL, iota, ra, dec, psi, z],\n",
    "    returns a 7-tuple of the\n",
    "    * redshift z,\n",
    "    * integrated snr,\n",
    "    * fractional Mc and DL and absolute eta and iota errors,\n",
    "    * 90% sky area.\n",
    "    sigma_log(Mc) = sigma_Mc/Mc is fractional error in Mc and similarly for DL, sigma_eta is absolute,\n",
    "    while |sigma_cos(iota)| = |sigma_iota*sin(iota)| --> error in iota requires rescaling from output\"\"\"\n",
    "    varied_keys = ['Mc', 'eta', 'chi1x', 'chi1y', 'chi1z', 'chi2x', 'chi2y', 'chi2z', 'DL', 'iota', 'ra', 'dec', 'psi', 'z']\n",
    "    varied_params = dict(zip(varied_keys, inj))\n",
    "    z = varied_params.pop('z')\n",
    "    Mc, eta, iota = varied_params['Mc'], varied_params['eta'], varied_params['iota']\n",
    "    \n",
    "    Mtot = Mc/eta**0.6\n",
    "    #fisco = (6**1.5*PI*Mtot)**-1 # missing some number of Msun, c=1, G=1 factors\n",
    "    fisco = 4.4/Mtot*1e3 # Hz # from https://arxiv.org/pdf/2011.05145.pdf\n",
    "    fmin, fmax, df = 5, min(coeff_fisco*fisco, 1024), 1/16 \n",
    "    f = np.arange(fmin, fmax, df)\n",
    "\n",
    "    # net_copy is automatically deleted once out of scope (is copying necessary with Pool()?)\n",
    "    net_copy = deepcopy(net)\n",
    "    inj_params = dict(**base_params, **varied_params)\n",
    "    net_copy.set_net_vars(f=f, inj_params=inj_params, deriv_symbs_string=deriv_symbs_string,\n",
    "                          conv_cos=conv_cos, conv_log=conv_log, use_rot=use_rot)\n",
    "\n",
    "    basic_network_benchmarking(net_copy, numerical_over_symbolic_derivs=True, only_net=only_net,\n",
    "                               numerical_deriv_settings=numerical_deriv_settings, hide_prints=True)\n",
    "\n",
    "    if net_copy.wc_fisher:\n",
    "        # convert sigma_cos(iota) into sigma_iota\n",
    "        abs_err_iota = abs(net_copy.errs['cos_iota']/np.sin(iota))\n",
    "        return (z, net_copy.snr, net_copy.errs['log_Mc'], net_copy.errs['log_DL'], net_copy.errs['eta'],\n",
    "                abs_err_iota, net_copy.errs['sky_area_90'])\n",
    "    else:\n",
    "        # to-do: check if CE only is still ill-conditioned\n",
    "        return (z, *np.full(6, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calculate_benchmark_from_injection(inj_data[0])\n",
    "# to-do: fix IndexError: index 0 is out of bounds for axis 0 with size 0 from inside nd.Gradient\n",
    "# something must be wrong here because the numerical differentiation works normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate results: z, snr, errs (logMc, logDL, eta, iota), sky area\n",
    "results = np.array(p_umap(calculate_benchmark_from_injection, inj_data, num_cpus=os.cpu_count()-1))\n",
    "# filter out NaNs\n",
    "results = without_rows_w_nan(results)\n",
    "if len(results) == 0:\n",
    "    print('All values are NaN, FIM is ill-conditioned.')\n",
    "np.save(f'data_B&S2022_replication/results_{file_tag}.npy', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load(f'data_B&S2022_replication/results_{file_tag}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use integrated SNR rho from standard benchmarking, not sure if B&S2022 use matched filter\n",
    "snr_threshold_lo = 10 # for detection\n",
    "snr_threshold_hi = 100 # for high fidelity\n",
    "for snr_threshold in snr_threshold_lo, snr_threshold_hi:\n",
    "    efficiency = np.mean(results[:,1] > snr_threshold)\n",
    "    print(f\"average efficiency over all z is {efficiency:.1%} wrt SNR threshold {snr_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: pass injection data to benchmarking, then calculate a detection rate!\n",
    "# injections.bns_md_merger_rate(0) # from z=0 outwards\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, ax = plt.subplots()\n",
    "zarr = np.logspace(np.log10(1e-2), np.log10(50), 100)\n",
    "ax.plot(zarr, list(map(injections.bns_md_merger_rate, zarr)))\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim((1e-2, 50))\n",
    "ax.set(xlabel='redshift, z', ylabel=r'merger rate / $\\mathrm{Gpc}^{-3} \\mathrm{yr}^{-1}$') # check units?\n",
    "plt.show(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: fit three-parameter sigmoids to efficiency curves vs redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: study BBH science case as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In fact, we see that the three generations (A+, Voyager, and NG) are qualitatively different\n",
    "with respect to every metric used in this study.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
