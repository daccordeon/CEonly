{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "James Gardner, 2022 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to analyse science case/s for CE only:\n",
    "\n",
    "CE-N 40km with CE-S 40km or 20km\n",
    "\n",
    "if done, then look at CE-S with one ET detector\n",
    "\n",
    "verify techniques by replicating *Borhanian and Sathya 2022*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking import *\n",
    "from gwbench.basic_relations import f_isco_Msolar\n",
    "\n",
    "from scipy.stats import gmean\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.integrate import quad\n",
    "from astropy.cosmology import Planck18\n",
    "from p_tqdm import p_map\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "# suppress warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# colours pulled from B&S2022 using Inkscape\n",
    "BS2022_STANDARD_6 = dict(nets=[\n",
    "    ['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I'],\n",
    "    ['V+_V', 'K+_K', 'Voyager-CBO_H', 'Voyager-CBO_L', 'Voyager-CBO_I'],\n",
    "    ['A+_H', 'A+_L', 'K+_K', 'A+_I', 'ET_ET1'],\n",
    "    ['V+_V', 'K+_K', 'A+_I', 'CE1-40-CBO_C'],\n",
    "    ['K+_K', 'A+_I', 'ET_ET1', 'CE1-40-CBO_C'],\n",
    "    ['ET_ET1', 'CE1-40-CBO_C', 'CE1-40-CBO_S']],\n",
    "    colours=['#8c510aff','#bf812dff','#dfc27dff','#80cdc1ff','#35978fff','#01665eff'])\n",
    "# https://flatuicolors.com/palette/us\n",
    "CE_ONLY = dict(nets=[\n",
    "    ['CE1-40-CBO_C', 'CE1-20-PMO_S'],\n",
    "    ['CE1-40-CBO_C', 'CE1-40-CBO_S'],\n",
    "    ['CE2-40-CBO_C', 'CE2-20-PMO_S'],\n",
    "    ['CE2-40-CBO_C', 'CE2-40-CBO_S']],\n",
    "    colours=['#a29bfe','#ff7675','#6c5ce7','#d63031'])\n",
    "CE_S_W_ET = dict(nets=[\n",
    "    ['CE1-20-PMO_S', 'ET_ET1'],\n",
    "    ['CE1-40-CBO_S', 'ET_ET1'],\n",
    "    ['CE2-20-PMO_S', 'ET_ET1'],\n",
    "    ['CE2-40-CBO_S', 'ET_ET1']],\n",
    "    colours=['#74b9ff','#fd79a8','#0984e3','#e84393'])\n",
    "# colour look-up given net_spec\n",
    "DICT_KEY_NETSPEC_VAL_COLOUR = dict()\n",
    "for dict_nets_colours in BS2022_STANDARD_6, CE_ONLY, CE_S_W_ET:\n",
    "    for net_spec in dict_nets_colours['nets']:\n",
    "        DICT_KEY_NETSPEC_VAL_COLOUR[repr(net_spec)] = dict_nets_colours['colours'][dict_nets_colours['nets'].index(net_spec)]\n",
    "\n",
    "HACK_DR_COEFF_BNS = 38\n",
    "HACK_DR_COEFF_BBH = 24\n",
    "def hack_coeff_default(science_case):\n",
    "    if science_case == 'BNS':\n",
    "        return HACK_DR_COEFF_BNS\n",
    "    elif science_case == 'BBH':\n",
    "        return HACK_DR_COEFF_BBH\n",
    "    else:\n",
    "        raise ValueError('Science case not recognised.')\n",
    "\n",
    "sigmoid_3parameter = lambda z, a, b, c : ((1+b)/(1+b*np.exp(a*z)))**c\n",
    "\n",
    "def save_benchmark_from_generated_injections(net, redshift_bins, num_injs,\n",
    "                                             mass_dict, spin_dict, redshifted,\n",
    "                                             base_params, deriv_symbs_string, coeff_fisco,\n",
    "                                             conv_cos, conv_log, use_rot, only_net,\n",
    "                                             numerical_over_symbolic_derivs, numerical_deriv_settings,\n",
    "                                             file_tag):\n",
    "    \"\"\"given network and variables, generate injections, benchmark, \n",
    "    and save results (snr, errors in logM logDL eta iota, sky area) as .npy\n",
    "    to-do: tidy up number of arguments\"\"\"\n",
    "    # injection and benchmarking\n",
    "    # concatenate injection data from different bins\n",
    "    inj_data = np.empty((len(redshift_bins)*num_injs, 14))\n",
    "    for i, (zmin, zmax, seed) in enumerate(redshift_bins):\n",
    "        cosmo_dict = dict(sampler='uniform', zmin=zmin, zmax=zmax)\n",
    "        # transposed array to get [[Mc0, eta0, ..., z0], [Mc1, eta1, ..., z1], ...]\n",
    "        # [Mc, eta, chi1x, chi1y, chi1z, chi2x, chi2y, chi2z, DL, iota, ra, dec, psi, z]    \n",
    "        inj_data[i*num_injs:(i+1)*num_injs] = np.array(injections.injections_CBC_params_redshift(cosmo_dict, mass_dict, spin_dict, redshifted, num_injs=num_injs, seed=seed)).transpose()\n",
    "\n",
    "    def calculate_benchmark_from_injection(inj):\n",
    "        \"\"\"given a 14-array of [Mc, eta, chi1x, chi1y, chi1z, chi2x, chi2y, chi2z, DL, iota, ra, dec, psi, z],\n",
    "        returns a 7-tuple of the\n",
    "        * redshift z,\n",
    "        * integrated snr,\n",
    "        * fractional Mc and DL and absolute eta and iota errors,\n",
    "        * 90% sky area.\n",
    "        sigma_log(Mc) = sigma_Mc/Mc is fractional error in Mc and similarly for DL, sigma_eta is absolute,\n",
    "        while |sigma_cos(iota)| = |sigma_iota*sin(iota)| --> error in iota requires rescaling from output\"\"\"\n",
    "        varied_keys = ['Mc', 'eta', 'chi1x', 'chi1y', 'chi1z', 'chi2x', 'chi2y', 'chi2z', 'DL', 'iota', 'ra', 'dec', 'psi', 'z']\n",
    "        varied_params = dict(zip(varied_keys, inj))\n",
    "        z = varied_params.pop('z')\n",
    "        Mc, eta, iota = varied_params['Mc'], varied_params['eta'], varied_params['iota']\n",
    "\n",
    "        Mtot = Mc/eta**0.6\n",
    "        #fisco = (6**1.5*PI*Mtot)**-1 # missing some number of Msun, c=1, G=1 factors\n",
    "        fisco = f_isco_Msolar(Mtot) #4.4/Mtot*1e3 # Hz # from https://arxiv.org/pdf/2011.05145.pdf\n",
    "        fmin, fmax = 5., float(max(min(coeff_fisco*fisco, 1024), 10)) # to stop f being too small\n",
    "        # select df from 1/16 (fine from B&S2022) to 10 (coarse) Hz\n",
    "        df = (fmax-fmin)/(1024-fmin)*10+(1024-fmax)/(1024-fmin)*1/16\n",
    "        f = np.arange(fmin, fmax, df)\n",
    "        # to diagnose len(f) == 1 error\n",
    "        if len(f) == 1: print(f, fmin, fmax, df, coeff_fisco, fisco)\n",
    "\n",
    "        # net_copy is automatically deleted once out of scope (is copying necessary with Pool()?)\n",
    "        net_copy = deepcopy(net)\n",
    "        inj_params = dict(**base_params, **varied_params)\n",
    "        net_copy.set_net_vars(f=f, inj_params=inj_params, deriv_symbs_string=deriv_symbs_string,\n",
    "                              conv_cos=conv_cos, conv_log=conv_log, use_rot=use_rot)\n",
    "\n",
    "        basic_network_benchmarking(net_copy, numerical_over_symbolic_derivs=numerical_over_symbolic_derivs, only_net=only_net,\n",
    "                                   numerical_deriv_settings=numerical_deriv_settings, hide_prints=True)\n",
    "\n",
    "        if net_copy.wc_fisher:\n",
    "            # convert sigma_cos(iota) into sigma_iota\n",
    "            abs_err_iota = abs(net_copy.errs['cos_iota']/np.sin(iota))\n",
    "            return (z, net_copy.snr, net_copy.errs['log_Mc'], net_copy.errs['log_DL'], net_copy.errs['eta'],\n",
    "                    abs_err_iota, net_copy.errs['sky_area_90'])\n",
    "        else:\n",
    "            # to-do: check if CE only is still ill-conditioned\n",
    "            return (z, *np.full(6, np.nan))\n",
    "\n",
    "    # calculate results: z, snr, errs (logMc, logDL, eta, iota), sky area\n",
    "    # p_umap is unordered in redshift for greater speed (check)\n",
    "    results = np.array(p_umap(calculate_benchmark_from_injection, inj_data, num_cpus=os.cpu_count()-1))\n",
    "    # filter out NaNs\n",
    "    results = without_rows_w_nan(results)\n",
    "    if len(results) == 0:\n",
    "        raise ValueError('All calculated values are NaN, FIM is ill-conditioned.')\n",
    "    np.save(f'data_redshift_snr_errs_sky-area/results_{file_tag}.npy', results)  \n",
    "    \n",
    "def calculate_detection_rate_from_results(results, science_case, print_reach=True, hack_merger_rate_coeff=None):\n",
    "    \"\"\"calculting efficiency and detection rate for plotting from results\"\"\"\n",
    "    # count efficiency over sources in (z, z+Delta_z)\n",
    "    zmin_plot, zmax_plot, num_zbins_fine = 1e-2, 50, 40 # eyeballing 40 bins from Fig 2\n",
    "    redshift_bins_fine = list(zip(np.geomspace(zmin_plot, zmax_plot, num_zbins_fine)[:-1],\n",
    "                                  np.geomspace(zmin_plot, zmax_plot, num_zbins_fine)[1:])) # redshift_bins are too wide\n",
    "    zavg_efflo_effhi = np.empty((len(redshift_bins_fine), 3))\n",
    "    for i, (zmin, zmax) in enumerate(redshift_bins_fine):\n",
    "        z_snr_in_bin = results[:,0:2][np.logical_and(zmin < results[:,0], results[:,0] < zmax)]\n",
    "        if len(z_snr_in_bin) == 0:\n",
    "            zavg_efflo_effhi[i] = [np.nan, np.nan, np.nan]\n",
    "        else:\n",
    "            zavg_efflo_effhi[i,0] = gmean(z_snr_in_bin[:,0]) # geometric mean, just using zmax is cleaner but less accurate\n",
    "            zavg_efflo_effhi[i,1] = np.mean(z_snr_in_bin[:,1] > SNR_THRESHOLD_LO)\n",
    "            zavg_efflo_effhi[i,2] = np.mean(z_snr_in_bin[:,1] > SNR_THRESHOLD_HI)\n",
    "    zavg_efflo_effhi = without_rows_w_nan(zavg_efflo_effhi)    \n",
    "\n",
    "    # fit three-parameter sigmoids to efficiency curves vs redshift\n",
    "    # using initial coeff guesses inspired by Table 9\n",
    "    # returns popts, pcovs\n",
    "    # needs high maxfev to converge\n",
    "    # can use bounds and maxfev together, stack exchange lied!\n",
    "    p0, bounds, maxfev = [5, 0.01, 0.1], [[0.03,5e-5,0.01], [600,0.2,2]], 1e5\n",
    "    popt_lo, _ = curve_fit(sigmoid_3parameter, zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,1],\n",
    "                             method='dogbox', p0=p0, bounds=bounds, maxfev=maxfev)\n",
    "    if np.all(zavg_efflo_effhi[:,2] == 0):\n",
    "        popt_hi = 1, -1, 1 # f(z) = 0\n",
    "    else:\n",
    "        popt_hi, _ = curve_fit(sigmoid_3parameter, zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,2],\n",
    "                             method='dogbox', p0=p0, bounds=bounds, maxfev=maxfev)\n",
    "    popts = [popt_lo, popt_hi]\n",
    "    \n",
    "#         perrs = [np.sqrt(np.diag(pcov)) for pcov in pcovs]\n",
    "    # lambdas in list comprehension are unintuitive, be explicit unless confident, see:\n",
    "    # https://stackoverflow.com/questions/6076270/lambda-function-in-list-comprehensions\n",
    "    # det_eff_fits = [(lambda z : sigmoid_3parameter(z, *popt)) for popt in popts]\n",
    "    det_eff_fits = [(lambda z : sigmoid_3parameter(z, *popts[0])), (lambda z : sigmoid_3parameter(z, *popts[1]))]\n",
    "    # print(f'input {p0}\\noptimal {list(popt)}\\nerrors {perr}')\n",
    "    \n",
    "    # from this point on, I sample the sigmoid fit to the raw data (e.g. for the detection rate)\n",
    "    # detection efficiency, interpolate from sigmoid fit\n",
    "    def det_eff(z, snr_threshold):\n",
    "        if snr_threshold == 10:\n",
    "            return det_eff_fits[0](z)\n",
    "        elif snr_threshold == 100:\n",
    "            return det_eff_fits[1](z)\n",
    "        else:\n",
    "            # to-do: add this feature\n",
    "            raise ValueError(\"SNR thresholds other than 10 or 100 are not yet supported\") \n",
    "\n",
    "    # calculate and print reach and horizon\n",
    "    # want initial guess to be near the transition (high derivative) part of the sigmoid, how?\n",
    "    reach_initial_guess = 0.1 # pulling from Table 3\n",
    "    reach_eff, horizon_eff = 0.5, 0.001    \n",
    "    for snr_threshold in (10, 100):\n",
    "        # fsolve finds a zero x* of f(x) near an initial guess x0\n",
    "        reach =   fsolve(lambda z : det_eff(z, snr_threshold) - reach_eff,   reach_initial_guess)[0]\n",
    "        # use the reach solution as the initial guess for the horizon since strong local slope there\n",
    "        horizon = fsolve(lambda z : det_eff(z, snr_threshold) - horizon_eff, reach)[0]\n",
    "        if print_reach:\n",
    "            print(f\"Given SNR threshold rho_* = {snr_threshold:3d}, reach ({1-reach_eff:.1%}) z_r = {reach:.3f} and horizon ({1-horizon_eff:.1%}) z_h = {horizon:.3f}\")\n",
    "            if reach == reach_initial_guess:\n",
    "                print('! Reach converged to initial guess, examine local slope.')\n",
    "        \n",
    "    # to-do: fix merger rate so that the plot reaches beyond 1e5 detections per year, maybe a units issue?\n",
    "    #merger_rate = lambda z: injections.bns_md_merger_rate(z) # too low (1e1) but below is too large (1e13)\n",
    "    # don't know if injections.bns_md_merger_rate(z) is R(z) or \\dot{n}(z) (merger rate density)\n",
    "    # bns_md_merger_rate_uniform_comoving_volume_redshift_inversion_sampler suggests the latter\n",
    "    # 4*pi to convert from Mpc^3 sr^-1 (sr is steradian)\n",
    "    differential_comoving_volume = lambda z : 4.*PI*Planck18.differential_comoving_volume(z).value # in Mpc^3\n",
    "    \n",
    "    # the merger rate is still incorrect, so experiment with the missing factor\n",
    "    if hack_merger_rate_coeff is None:\n",
    "        hack_merger_rate_coeff = 1\n",
    "    elif hack_merger_rate_coeff == 'default':\n",
    "        hack_merger_rate_coeff = hack_coeff_default(science_case)\n",
    "    # 1e-9 converts Gpc^-3 to Mpc^-3 to match Planck18\n",
    "    if science_case == 'BNS':\n",
    "        merger_rate = lambda z: hack_merger_rate_coeff*1e-9*injections.bns_md_merger_rate(z)*differential_comoving_volume(z) # now in yr^-1? what is bns_md..._rate in?\n",
    "        # want merger rate density in Mpc^-3 yr^-1, not just 1e-9 difference (e.g. Mpc^3 to Gpc^3) or c\n",
    "    elif science_case == 'BBH':\n",
    "        # to-do: figure out remaining missing factors\n",
    "        # injections.py mentions an old arXiv version: https://arxiv.org/pdf/2012.09876v1.pdf\n",
    "        # this states that the ndot form in injections.py is just a proportionality relation\n",
    "        # in Fig 2 of Ngetal2021: the ndot_F rate is in Gpc^-3 yr^-1\n",
    "        # --> there is a conversion/units factor missing in my calculation! to-do: find out what it is.\n",
    "        merger_rate = lambda z: hack_merger_rate_coeff*1e-9*injections.mdbn_merger_rate(z)*differential_comoving_volume(z)\n",
    "    else:\n",
    "        raise ValueError('Science case not recognised.')    \n",
    "\n",
    "    # i.e. \"merger rate\" in Fig 2, not R(z) but int R(z)/(1+z), i.e. if perfect efficiency, quad returns (value, error)\n",
    "    # 1+z factor of time dilation of merger rate in observer frame z away\n",
    "    det_rate_limit = lambda z0 : quad(lambda z : merger_rate(z)/(1+z), 0, z0)[0]\n",
    "    # detection rate\n",
    "    det_rate = lambda z0, snr_threshold : quad(lambda z : det_eff(z, snr_threshold)*merger_rate(z)/(1+z), 0, z0)[0]    \n",
    "    return zavg_efflo_effhi, det_eff_fits, det_rate_limit, det_rate, zmin_plot, zmax_plot\n",
    "    \n",
    "def plot_snr_eff_detrate_vs_redshift(results, zavg_efflo_effhi,\n",
    "                                    det_eff_fits, det_rate_limit, det_rate,\n",
    "                                    zmin_plot, zmax_plot,\n",
    "                                    file_tag, human_file_tag, show_fig=True,\n",
    "                                    print_progress=True, hack_merger_rate_coeff=None):\n",
    "    \"\"\"plotting to replicate Fig 2 in B&S2022\n",
    "    to-do: tidy up number of arguments\"\"\"   \n",
    "    # switching to using the same colour but different linestyles for LO and HI SNR threshold\n",
    "#     colours = 'darkred', 'red'\n",
    "    colour = 'C0'\n",
    "    zaxis_plot = np.geomspace(zmin_plot, zmax_plot, 100)\n",
    "\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, axs = plt.subplots(3, 1, sharex=True, figsize=(6, 12), gridspec_kw={'wspace':0, 'hspace':0.05})\n",
    "\n",
    "    # SNR vs redshift\n",
    "    # use integrated SNR rho from standard benchmarking, not sure if B&S2022 use matched filter\n",
    "    axs[0].loglog(results[:,0], results[:,1], '.')\n",
    "    axs[0].axhspan(0, SNR_THRESHOLD_LO, alpha=0.5,  color='lightgrey')\n",
    "    axs[0].axhspan(0, SNR_THRESHOLD_HI, alpha=0.25, color='lightgrey')\n",
    "    axs[0].set_ylabel(r'integrated SNR, $\\rho$')\n",
    "    axs[0].set_title(human_file_tag, fontsize=14)\n",
    "\n",
    "    # efficiency vs redshift\n",
    "    axs[1].axhline(0, color='grey', linewidth=0.5)\n",
    "    axs[1].axhline(1, color='grey', linewidth=0.5)\n",
    "    axs[1].plot(zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,1], 'o', color=colour, label=fr'$\\rho$ > {SNR_THRESHOLD_LO}')\n",
    "    axs[1].plot(zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,2], 's', color=colour, label=fr'$\\rho$ > {SNR_THRESHOLD_HI}')\n",
    "    axs[1].semilogx(zaxis_plot, det_eff_fits[0](zaxis_plot), '-',  color=colour)\n",
    "    axs[1].semilogx(zaxis_plot, det_eff_fits[1](zaxis_plot), '--', color=colour)\n",
    "    handles, labels = axs[1].get_legend_handles_labels()\n",
    "    new_handles = list(np.array([[\n",
    "        mlines.Line2D([], [], marker='o', linestyle='-',  color=colour),\n",
    "        mlines.Line2D([], [], marker='s', linestyle='--', color=colour)] for handle in handles[::2]]).flatten())\n",
    "    axs[1].legend(handles=new_handles, labels=labels, handlelength=2)   \n",
    "    axs[1].set_ylim((0-0.05, 1+0.05))\n",
    "    axs[1].set_ylabel(r'detection efficiency, $\\varepsilon$')\n",
    "    fig.align_ylabels()\n",
    "\n",
    "    # detection rate vs redshift\n",
    "    # merger rate depends on star formation rate and the delay between formation and merger\n",
    "    axs[2].loglog(zaxis_plot, list(p_map(det_rate_limit, zaxis_plot)), color='black', linewidth=1)\n",
    "    axs[2].loglog(zaxis_plot, list(p_map(lambda z : det_rate(z, snr_threshold=10),  zaxis_plot)), '-',  color=colour)\n",
    "    axs[2].loglog(zaxis_plot, list(p_map(lambda z : det_rate(z, snr_threshold=100), zaxis_plot)), '--', color=colour)\n",
    "    axs[2].set_ylim((1e-1, 6e5)) # to match B&S2022 Fig 2\n",
    "    if print_progress: print('Detection rate calculated.')\n",
    "    if hack_merger_rate_coeff is not None:\n",
    "        if hack_merger_rate_coeff == 'default':\n",
    "            hack_merger_rate_coeff = hack_coeff_default(science_case)\n",
    "        axs[2].set_ylabel(r'detection rate, $D_R$ / $\\mathrm{{yr}}^{{-1}}$'+f'\\nhack co-efficient: {hack_merger_rate_coeff}', color='red') # is wrong!\n",
    "        axs[2].tick_params(axis='y', colors='red') \n",
    "    else:\n",
    "        axs[2].set_ylabel(r'detection rate, $D_R$ / $\\mathrm{yr}^{-1}$')  \n",
    "    axs[-1].set_xscale('log')\n",
    "    axs[-1].set_xlim((zmin_plot, zmax_plot))\n",
    "    axs[-1].xaxis.set_minor_locator(plt.LogLocator(base=10.0, subs=0.1*np.arange(1, 10), numticks=10))\n",
    "    axs[-1].xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "    axs[-1].set_xlabel('redshift, z')\n",
    "\n",
    "    fig.savefig(f'plots/snr_eff_rate_vs_redshift_{file_tag}.pdf', bbox_inches='tight')\n",
    "    if show_fig:\n",
    "        plt.show(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "# # direct substitution doesn't work because pool.map and p_map work differently, e.g. the latter can take lambdas \n",
    "# from multiprocessing import Pool\n",
    "# def p_map_no_tqdm(f, x):\n",
    "#     \"\"\"to use in optional arguments to hide progress bars\n",
    "#     uses one less than the available cpus to enable navigation\"\"\"\n",
    "#     with Pool(processes=os.cpu_count()-1) as pool:\n",
    "#         return pool.map(f, x)\n",
    "\n",
    "# Replicating Borhanian and Sathya 2022 injections and detection rates\n",
    "def detection_rate_for_network_and_waveform(network_spec, science_case, wf_model_name, wf_other_var_dic, num_injs,\n",
    "                                            show_fig=True, print_progress=True, print_reach=True, hack_merger_rate_coeff=None):\n",
    "    \"\"\"initialises network, benchmarks, calculates detection rate, plots\"\"\"\n",
    "    # initialisation\n",
    "    locs = [x.split('_')[-1] for x in network_spec]\n",
    "    net = network.Network(network_spec)\n",
    "    net.set_wf_vars(wf_model_name=wf_model_name, wf_other_var_dic=wf_other_var_dic)\n",
    "    \n",
    "    if science_case == 'BNS':\n",
    "        # injection settings - source\n",
    "        mass_dict = dict(dist='gaussian', mean=1.35, sigma=0.15, mmin=1, mmax=2)\n",
    "        spin_dict = dict(geom='cartesian', dim=1, chi_lo=-0.05, chi_hi=0.05)\n",
    "        # zmin, zmax, seed (use same seeds to replicate results)\n",
    "        # typo in AppA that starts at 0 rather than 0.02 (in main text)?\n",
    "        redshift_bins = ((0.02, 0.5, 7669), (0.5, 1, 3103), (1, 2, 4431), (2, 4, 5526), (4, 10, 7035), (10, 50, 2785))\n",
    "        coeff_fisco = 4 # fmax = 4*fisco for BNS, 8*fisco for BBH\n",
    "    elif science_case == 'BBH':\n",
    "        # following injection.py and GWTC-2 (AppB.2. Power Law + Peak mass model), to-do: update for GWTC-3?\n",
    "        # m1 follows power peak, m2 follow uniform in (5 Msun, m1) --> change mmin to 5?\n",
    "        mass_dict = dict(\n",
    "            dist='power_peak_uniform',\n",
    "            mmin       = 5, # 4.59 in GWTC-2, but changing to 5 here to get m2 in correct range\n",
    "            mmax       = 86.22,\n",
    "            m1_alpha   = 2.63,\n",
    "            q_beta     = 1.26,\n",
    "            peak_frac  = 0.1,\n",
    "            peak_mean  = 33.07, # assuming that peak_mu is peak_mean?\n",
    "            peak_sigma = 5.69,\n",
    "            delta_m    = 4.82,\n",
    "        )\n",
    "        spin_dict = dict(geom='cartesian', dim=1, chi_lo=-0.75, chi_hi=0.75)\n",
    "        redshift_bins = ((0.02, 0.5, 5485), (0.5, 1, 1054), (1, 2, 46), (2, 4, 5553), (4, 10, 5998), (10, 50, 4743))\n",
    "        coeff_fisco = 8\n",
    "    else:\n",
    "        raise ValueError('Science case not recognised.')\n",
    "\n",
    "    base_params = {\n",
    "        'tc':    0,\n",
    "        'phic':  0,\n",
    "        'gmst0': 0, # assume zero given B2021\n",
    "        # to-do: find correct tidal parameters\n",
    "        'lam_t': 800, # combined dimensionless tidal deformability, 800 for GW170817, to-do: what did B&S2022 use?\n",
    "        'delta_lam_t': 0, # assuming zero but can be calculated if m1, m2, Love number, and EoS (i.e. radii) known\n",
    "    }\n",
    "\n",
    "    # derivative settings\n",
    "    # assign with respect to which parameters to take derivatives for the FIM\n",
    "    deriv_symbs_string = 'Mc eta DL tc phic iota ra dec psi'\n",
    "    # assign which parameters to convert to log or cos versions for differentiation\n",
    "    conv_cos = ('dec', 'iota')\n",
    "    conv_log = ('Mc', 'DL', 'lam_t')\n",
    "\n",
    "    # network settings: whether to include Earth's rotation and individual detector calculations\n",
    "    use_rot = 1\n",
    "    only_net = 1\n",
    "\n",
    "    # injection settings - other: number of injections per redshift bin (over 6 bins)\n",
    "    redshifted = 1 # whether sample masses already redshifted wrt z\n",
    "    if wf_other_var_dic is not None:\n",
    "        file_tag = f'NET_{net.label}_SCI-CASE_{science_case}_WF_{wf_model_name}_{wf_other_var_dic[\"approximant\"]}_NUM-INJS_{num_injs}'\n",
    "        human_file_tag = f'network: {net.label.replace(\"..\", \", \")}\\nscience case: {science_case}\\nwaveform: {wf_model_name} with {wf_other_var_dic[\"approximant\"]}\\nnumber of injections per bin: {num_injs}'\n",
    "    else:\n",
    "        file_tag = f'NET_{net.label}_SCI-CASE_{science_case}_WF_{wf_model_name}_NUM-INJS_{num_injs}'\n",
    "        human_file_tag = f'network: {net.label.replace(\"..\", \", \")}\\nscience case: {science_case}\\nwaveform: {wf_model_name}\\nnumber of injections per bin: {num_injs}'    \n",
    "    \n",
    "    if print_progress: print('Network initialised.')\n",
    "    # use symbolic derivatives if able\n",
    "    if (wf_model_name == 'tf2') | (wf_model_name == 'tf2_tidal'):\n",
    "        numerical_over_symbolic_derivs = False    \n",
    "        generate_symbolic_derivatives(wf_model_name, wf_other_var_dic, deriv_symbs_string, locs, use_rot, print_progress=print_progress)\n",
    "        numerical_deriv_settings = None\n",
    "    else:\n",
    "        numerical_over_symbolic_derivs = True\n",
    "        numerical_deriv_settings = dict(step=1e-9, method='central', order=2, n=1) # default\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # generate results or skip if previously generated successfully (i.e. not ill-conditioned)\n",
    "    if not os.path.isfile(f'data_redshift_snr_errs_sky-area/results_{file_tag}.npy'):\n",
    "        save_benchmark_from_generated_injections(net, redshift_bins, num_injs,\n",
    "                                                mass_dict, spin_dict, redshifted,\n",
    "                                                base_params, deriv_symbs_string, coeff_fisco,\n",
    "                                                conv_cos, conv_log, use_rot, only_net,\n",
    "                                                numerical_over_symbolic_derivs, numerical_deriv_settings,\n",
    "                                                file_tag)\n",
    "\n",
    "    results = np.load(f'data_redshift_snr_errs_sky-area/results_{file_tag}.npy')\n",
    "    if print_progress: print('Results found and loaded.')\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # calculting efficiency and detection rate for plotting\n",
    "    zavg_efflo_effhi, det_eff_fits, det_rate_limit, det_rate, zmin_plot, zmax_plot = \\\n",
    "        calculate_detection_rate_from_results(results, science_case, print_reach, hack_merger_rate_coeff=hack_merger_rate_coeff)\n",
    "    \n",
    "    if print_progress: print('Detection rate defined, now calculating...')\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # plotting\n",
    "    plot_snr_eff_detrate_vs_redshift(results,\n",
    "                                     zavg_efflo_effhi, det_eff_fits, det_rate_limit, det_rate, zmin_plot, zmax_plot,\n",
    "                                     file_tag, human_file_tag, show_fig=show_fig,\n",
    "                                     print_progress=print_progress, hack_merger_rate_coeff=hack_merger_rate_coeff)\n",
    "    \n",
    "# Collating different networks saved using the above method to generate B&S2022 Fig 2\n",
    "def collate_eff_detrate_vs_redshift(axs,\n",
    "                                    zavg_efflo_effhi, det_eff_fits, det_rate_limit, det_rate, zaxis_plot,\n",
    "                                    colours=None, label=None):\n",
    "    \"\"\"collate plots to replicate Fig 2 in B&S2022, adds curves to existing axs\n",
    "    defaults to using the same colour\"\"\"\n",
    "    if colours is None:\n",
    "        colours = [None, None] # list is mutable, None is not\n",
    "\n",
    "    # efficiency vs redshift\n",
    "    # re-ordered plots to re-order legend\n",
    "    line_lo, = axs[0].semilogx(zaxis_plot, det_eff_fits[0](zaxis_plot), color=colours[0], label=label)\n",
    "    if colours[1] is None:\n",
    "        colours[1] = line_lo.get_color()    \n",
    "    line_hi, = axs[0].semilogx(zaxis_plot, det_eff_fits[1](zaxis_plot), color=colours[1], linestyle='--')    \n",
    "    axs[0].plot(zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,1], 'o', color=line_lo.get_color(), label=fr'$\\rho$ > {SNR_THRESHOLD_LO}')\n",
    "    axs[0].plot(zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,2], 's', color=line_hi.get_color(), label=fr'$\\rho$ > {SNR_THRESHOLD_HI}')\n",
    "\n",
    "    # explicitly setting legend\n",
    "#     plt.plot(np.linspace(1, 1000, 10), np.arange(10), 'o-', label='test')\n",
    "#     plt.plot(np.linspace(1, 1000, 10), np.arange(10), 's--', label='test2')\n",
    "#     plt.legend()\n",
    "    \n",
    "    # detection rate vs redshift\n",
    "    # merger rate depends on star formation rate and the delay between formation and merger\n",
    "    axs[1].loglog(zaxis_plot, list(p_map(lambda z : det_rate(z, snr_threshold=10), zaxis_plot)),  color=line_lo.get_color())\n",
    "    axs[1].loglog(zaxis_plot, list(p_map(lambda z : det_rate(z, snr_threshold=100), zaxis_plot)), color=line_hi.get_color(), linestyle='--')\n",
    "\n",
    "def file_name_to_multiline_readable(file, two_rows_only=False, net_only=False):\n",
    "    intermediate = file.replace('results_', '').replace('.npy', '').replace('NET_', 'network: ').replace('_SCI-CASE_', '\\nscience case: ').replace('..', ', ')\n",
    "    if net_only:\n",
    "        return intermediate.split('\\n')[0]\n",
    "    else:\n",
    "        if two_rows_only:\n",
    "            return intermediate.replace('_WF_', ', waveform: ').replace('_NUM-INJS_', \", injections per bin: \")\n",
    "        else:\n",
    "            return intermediate.replace('_WF_', '\\nwaveform: ').replace('_NUM-INJS_', \"\\ninjections per bin: \")\n",
    "\n",
    "flatten_list = lambda x : [z for y in x for z in y] # x = [y, ...], y = [z, ...]\n",
    "\n",
    "def compare_networks_from_saved_results(network_spec_list, science_case, save_fig=True, show_fig=True, plot_label=None, full_legend=False, specific_wf=None, hack_merger_rate_coeff=None):\n",
    "    \"\"\"replication of Fig 2 in B&S2022, use to check if relative detection rates are correct\n",
    "    even if the absolute detection rate is wildly (1e9) off\n",
    "    network_spec_list is assumed unique\"\"\"\n",
    "    # finding file names\n",
    "    net_labels = [network.Network(network_spec).label for network_spec in network_spec_list]\n",
    "    if plot_label is None:\n",
    "        plot_label = f\"SCI-CASE_{science_case}{''.join(tuple('_NET_'+l for l in net_labels))}\"\n",
    "    \n",
    "    file_list = os.listdir(\"data_redshift_snr_errs_sky-area\")\n",
    "    found_files = np.array([])\n",
    "    for net_label in net_labels:\n",
    "        # file_tag = f'NET_{net.label}_SCI-CASE_{science_case}_WF_..._NUM-INJS_{num_injs}'\n",
    "        file_tag_partial = f'NET_{net_label}_SCI-CASE_{science_case}'\n",
    "        # file is file_name\n",
    "        matches = np.array([file for file in file_list if file_tag_partial in file])\n",
    "        if len(matches) == 0:\n",
    "            continue\n",
    "        # [[f'NET_{net.label}_SCI-CASE_{science_case}', f'{wf_model_name}', f'{num_injs}', '.npy'], [...], ...]\n",
    "        decomp_files = np.array([file.replace('.npy', '').replace('_WF_', '_NUM-INJS_').split('_NUM-INJS_') for file in matches])\n",
    "        # appending is slow but this problem is small\n",
    "        unique_wf_index_list = []\n",
    "        for i, wf in enumerate(decomp_files[:,1]):\n",
    "            # if specified a wf (with any auxillary), then skip all those that don't match\n",
    "            if specific_wf is not None:\n",
    "                if wf != specific_wf:\n",
    "                    continue\n",
    "    \n",
    "            if np.sum(decomp_files[:,1] == wf) == 1:\n",
    "                unique_wf_index_list.append(i)\n",
    "            else:\n",
    "                # if multiple files with same tag, then select the one with the greatest number of injections\n",
    "                num_injs_list = decomp_files[:,2][decomp_files[:,1] == wf]\n",
    "                unique_wf_index_list.append(num_injs_list.argmax())\n",
    "        found_files = np.append(found_files, matches[list(set(unique_wf_index_list))])\n",
    "    found_files = found_files.flatten()\n",
    "    if len(found_files) == 0:\n",
    "        raise ValueError('No files found.')\n",
    "    else:\n",
    "        print(f'Found {len(found_files)} file/s:', *found_files, sep='\\n')\n",
    "       \n",
    "    # load file and add results to plot\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, axs = plt.subplots(2, 1, sharex=True, figsize=(6, 8), gridspec_kw={'wspace':0, 'hspace':0.05})\n",
    "    zaxis_plot = np.geomspace(1e-2, 50, 100)\n",
    "    \n",
    "    axs[0].axhline(0, color='grey', linewidth=0.5)\n",
    "    axs[0].axhline(1, color='grey', linewidth=0.5)\n",
    "    axs[0].set_ylim((0-0.05, 1+0.05))\n",
    "    axs[0].set_ylabel(r'detection efficiency, $\\varepsilon$')\n",
    "    axs[1].set_ylim((1e-1, 6e5)) # to match B&S2022 Fig 2    \n",
    "    if hack_merger_rate_coeff is not None:\n",
    "        if hack_merger_rate_coeff == 'default':\n",
    "            hack_merger_rate_coeff = hack_coeff_default(science_case)\n",
    "        axs[1].set_ylabel(r'detection rate, $D_R$ / $\\mathrm{{yr}}^{{-1}}$'+f'\\nhack co-efficient: {hack_merger_rate_coeff}', color='red') # is wrong!\n",
    "        axs[1].tick_params(axis='y', colors='red') \n",
    "    else:\n",
    "        axs[1].set_ylabel(r'detection rate, $D_R$ / $\\mathrm{yr}^{-1}$')  \n",
    "    fig.align_ylabels()\n",
    "    axs[-1].set_xscale('log')\n",
    "    axs[-1].set_xlim((zaxis_plot[0], zaxis_plot[-1]))\n",
    "    axs[-1].xaxis.set_minor_locator(plt.LogLocator(base=10.0, subs=0.1*np.arange(1, 10), numticks=10))\n",
    "    axs[-1].xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "    axs[-1].set_xlabel('redshift, z')    \n",
    "#     axs[-1].grid(True, which='both')\n",
    "    \n",
    "    colours_used = []\n",
    "    for i, file in enumerate(found_files):\n",
    "        results = np.load(f'data_redshift_snr_errs_sky-area/{file}')\n",
    "        with HiddenPrints():\n",
    "            zavg_efflo_effhi, det_eff_fits, det_rate_limit, det_rate, _, _ = \\\n",
    "                calculate_detection_rate_from_results(results, science_case, print_reach=False, hack_merger_rate_coeff=hack_merger_rate_coeff)    \n",
    "        # to not repeatedly plot merger rate\n",
    "        if i == 0:\n",
    "            axs[1].loglog(zaxis_plot, list(p_map(det_rate_limit, zaxis_plot)), color='black', linewidth=3, label=f'{science_case} merger rate')\n",
    "#             print(f'maximum detection rate at z={zaxis_plot[-1]} is {det_rate_limit(zaxis_plot[-1])}')\n",
    "        \n",
    "        if full_legend:\n",
    "            label = file_name_to_multiline_readable(file, two_rows_only=True)\n",
    "        else:\n",
    "            label = file_name_to_multiline_readable(file, net_only=True)\n",
    "            \n",
    "        net_spec = file.replace('NET_', '_SCI-CASE_').split('_SCI-CASE_')[1].split('..')\n",
    "\n",
    "        if repr(net_spec) in DICT_KEY_NETSPEC_VAL_COLOUR.keys():\n",
    "            colour = DICT_KEY_NETSPEC_VAL_COLOUR[repr(net_spec)]\n",
    "            # avoid duplicating colours in plot\n",
    "            if colour in colours_used:\n",
    "                colour = None\n",
    "            else:\n",
    "                colours_used.append(colour)\n",
    "        else:\n",
    "            colour = None\n",
    "\n",
    "        collate_eff_detrate_vs_redshift(axs, zavg_efflo_effhi, det_eff_fits, det_rate_limit, det_rate, zaxis_plot, label=label, colours=[colour, colour])\n",
    "\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    # updating handles\n",
    "    new_handles = list(np.array([[\n",
    "        mlines.Line2D([], [], visible=False),\n",
    "        mlines.Line2D([], [], marker='o', linestyle='-', color=handle.get_c()),\n",
    "        mlines.Line2D([], [], marker='s', linestyle='--', color=handle.get_c())] for handle in handles[::3]]).flatten())\n",
    "    axs[0].legend(handles=new_handles, labels=labels, handlelength=2, bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    axs[1].legend(handlelength=2, loc=\"upper left\")\n",
    "    if save_fig:\n",
    "        fig.savefig(f'plots/collated_eff_rate_vs_z_{plot_label}.pdf', bbox_inches='tight')\n",
    "    if show_fig:\n",
    "        plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicating Borhanian and Sathya 2022 injections and detection rates, then for CE only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure: network, injection loop (inj, benchmark, save data), plot snr histogram, ...\n",
    "# ... calculate efficiency, calculate detection rate\n",
    "\n",
    "# try for this network, then CE only (refer to App E for CE discussion), compare to other five in Section 2a?\n",
    "# --- HLVKI+ ---\n",
    "# network_spec = ['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I']\n",
    "# --- VK+HLIv ---\n",
    "# network_spec = ['V+_V', 'K+_K', 'Voyager-CBO_H', 'Voyager-CBO_L', 'Voyager-CBO_I']\n",
    "# --- HLKI+E ---\n",
    "network_spec = ['A+_H', 'A+_L', 'K+_K', 'A+_I', 'ET_ET1'] # _E incorrect\n",
    "# --- VKI+C ---\n",
    "# network_spec = ['V+_V', 'K+_K', 'A+_I', 'CE1-40-CBO_C']\n",
    "# --- KI+EC ---\n",
    "# network_spec = ['K+_K', 'A+_I', 'ET_ET1', 'CE1-40-CBO_C']\n",
    "# --- ECS ---\n",
    "# network_spec = ['ET_ET1', 'CE1-40-CBO_C', 'CE1-40-CBO_S']\n",
    "# !--- CE only ---!\n",
    "# network_spec = ['CE1-40-CBO_C', 'CE1-40-CBO_S'] # --> FIM still ill-conditioned (for BNS, check BBH)\n",
    "# network_spec = ['CE2-40-CBO_C', 'CE2-40-CBO_S']\n",
    "# network_spec = ['CE1-40-CBO_C', 'CE1-20-PMO_S']\n",
    "# network_spec = ['CE2-40-CBO_C', 'CE2-20-PMO_S']\n",
    "\n",
    "# waveform and science case: 'BNS' or 'BBH'\n",
    "# to-do: add CBO vs PMO distinction\n",
    "# waveform, LAL list: https://lscsoft.docs.ligo.org/lalsuite/lalsimulation/group___l_a_l_sim_inspiral__h.html\n",
    "# --- BNS ---\n",
    "science_case = 'BNS'\n",
    "# wf_model_name, wf_other_var_dic = 'lal_bns', dict(approximant='IMRPhenomD')\n",
    "# wf_model_name, wf_other_var_dic = 'lal_bns', dict(approximant='IMRPhenomD_NRTidalv2') # for tidal, see https://arxiv.org/abs/1905.06011\n",
    "# to-do: missing dimensionless tidal parameters, calculate tidal parameters from sampled m1, m2 in injections.py? requires Love number and radii (i.e. choose an EoS)\n",
    "# --- BBH ---\n",
    "# science_case = 'BBH'\n",
    "# wf_model_name, wf_other_var_dic = 'lal_bbh', dict(approximant='IMRPhenomHM')\n",
    "# --- analytic waveforms ---\n",
    "# wf_model_name, wf_other_var_dic = 'tf2', None # to-do: stop using this once tidal params found\n",
    "wf_model_name, wf_other_var_dic = 'tf2_tidal', None\n",
    "\n",
    "# number of injections per redshift bin (6 bins)\n",
    "# start with 10, then build to 1e6 (how did they compute 1e6 with numerical derivs? many cores!)\n",
    "num_injs = 10\n",
    "\n",
    "detection_rate_for_network_and_waveform(network_spec, science_case, wf_model_name, wf_other_var_dic, num_injs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch for given science case\n",
    "# --- BNS ---\n",
    "# science_case = 'BNS'\n",
    "# wf_model_name, wf_other_var_dic = 'lal_bns', dict(approximant='IMRPhenomD_NRTidalv2') # for tidal, see https://arxiv.org/abs/1905.06011\n",
    "# to-do: missing dimensionless tidal parameters, calculate tidal parameters from sampled m1, m2 in injections.py? requires Love number and radii (i.e. choose an EoS)\n",
    "# --- BBH ---\n",
    "science_case = 'BBH'\n",
    "wf_model_name, wf_other_var_dic = 'lal_bbh', dict(approximant='IMRPhenomHM')\n",
    "# --- analytic waveforms ---\n",
    "# wf_model_name, wf_other_var_dic = 'tf2', None # to-do: stop using this once tidal params found\n",
    "# wf_model_name, wf_other_var_dic = 'tf2_tidal', None\n",
    "\n",
    "num_injs = 10\n",
    "\n",
    "# network_spec_list = BS2022_STANDARD_6['nets']\n",
    "# network_spec_list = CE_ONLY['nets']\n",
    "network_spec_list = CE_S_W_ET['nets']\n",
    "\n",
    "for network_spec in tqdm(network_spec_list):\n",
    "    detection_rate_for_network_and_waveform(network_spec, science_case, wf_model_name, wf_other_var_dic, num_injs,\n",
    "                                            show_fig=False, print_progress=False, print_reach=False,\n",
    "                                            hack_merger_rate_coeff='default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating different networks saved using the above method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch for both BBH and BNS science cases\n",
    "# ! remember to update plot label for each case else the plot will be overwritten\n",
    "compare_networks_from_saved_results(BS2022_STANDARD_6['nets'],\n",
    "                                    'BBH',\n",
    "                                    plot_label=\"SCI-CASE_BBH_NET_standard_6\", show_fig=False,\n",
    "                                    hack_merger_rate_coeff='default')\n",
    "\n",
    "# CE only, with 2G+ as a reference\n",
    "compare_networks_from_saved_results(CE_ONLY['nets'] + [['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I'],],\n",
    "                                    'BBH',\n",
    "                                    plot_label=\"SCI-CASE_BBH_NET_CE_only\", show_fig=False,\n",
    "                                    hack_merger_rate_coeff='default') \n",
    "\n",
    "compare_networks_from_saved_results(BS2022_STANDARD_6['nets'],\n",
    "                                    'BNS',\n",
    "                                    plot_label=\"SCI-CASE_BNS_NET_standard_6_WF_tf2_tidal\",\n",
    "                                    specific_wf='tf2_tidal', show_fig=False,\n",
    "                                    hack_merger_rate_coeff='default') \n",
    "\n",
    "compare_networks_from_saved_results(CE_ONLY['nets'] + [['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I'],],\n",
    "                                    'BNS',\n",
    "                                    plot_label=\"SCI-CASE_BNS_NET_CE_only_WF_tf2_tidal\",\n",
    "                                    specific_wf='tf2_tidal', show_fig=False,\n",
    "                                    hack_merger_rate_coeff='default') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CE South with one ET detector\n",
    "compare_networks_from_saved_results(CE_S_W_ET['nets'] + [['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I'],],\n",
    "                                    'BBH',\n",
    "                                    plot_label=\"SCI-CASE_BBH_NET_CE-S..ET\", show_fig=False,\n",
    "                                    hack_merger_rate_coeff='default') \n",
    "\n",
    "compare_networks_from_saved_results(CE_S_W_ET['nets'] + [['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I'],],\n",
    "                                    'BNS',\n",
    "                                    plot_label=\"SCI-CASE_BNS_NET_CE-S..ET_WF_tf2_tidal\",\n",
    "                                    specific_wf='tf2_tidal', show_fig=False,\n",
    "                                    hack_merger_rate_coeff='default') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: fix merger rate --- find proportionality constant --- to achieve 1e5 per year at z=1 (BBH) z=3 (BNS)\n",
    "# i.e. stop using hack merger rate coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: stop CE alone being ill-conditioned, seems to work for BBH numeric wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: fix BNS numerical waveform, current error \"numpy.linalg.LinAlgError: Array must not contain infs or NaNs\" with HLVKI+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: change sigmoid fits to global optimisation to avoid needing the initial guesses in B&S2022, this is not possible with scipy, need to write my own or source a global curve fitting (apparantly a non-trivial problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: refactor two plotting functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: fix BBH for large num_injs, error with frequency array f being too small for M large? --> decrease df \n",
    "# gets stuck towards end of progress bar consistently\n",
    "# IndexError: index 1 is out of bounds for axis 0 with size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: increase sampling below 4e-2, but App A uses (0, 0.5, seed)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: tidy up refactoring, reduce total number of arguments with unpacking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In fact, we see that the three generations (A+, Voyager, and NG) are qualitatively different\n",
    "with respect to every metric used in this study.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
