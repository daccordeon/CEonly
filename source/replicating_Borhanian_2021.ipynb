{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841bbf66",
   "metadata": {},
   "source": [
    "James Gardner, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6755205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_benchmarking import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199fa2c",
   "metadata": {},
   "source": [
    "### Replicating Fig 3 from Borhanian 2021 to test understanding, then try for CE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for GW170817 and tf2_tidal\n",
    "\n",
    "# select network\n",
    "net, locs = network.Network(['aLIGO_H','aLIGO_L','aLIGO_V']), ['H', 'L', 'V']\n",
    "# net, locs = network.Network(['CE1-40-CBO_C', 'CE1-40-CBO_S']), ['C', 'S']\n",
    "# to-do: for CE only, the FIM is ill-conditioned, how to fix this?\n",
    "\n",
    "# not stated, using one from GW170817 paper\n",
    "# start with 100 sample points, then move up from there (e.g. to 1e4)\n",
    "fmin, fmax, fnum = 30, 2048, 100\n",
    "f = np.linspace(fmin, fmax, fnum)\n",
    "\n",
    "wf_model_name = 'tf2_tidal'\n",
    "wf_other_var_dic = None\n",
    "net.set_wf_vars(wf_model_name=wf_model_name)\n",
    "\n",
    "# injection parameters for GW170817, reported median values (source-frame)\n",
    "# using low-spin priors (Borhanian doesn't say which they used)\n",
    "# https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.119.161101\n",
    "# subsequent work (2019) has refined these values\n",
    "base_measured_params = {\n",
    "    'Mc':    1.188, # Msun\n",
    "    'eta':   0.2485, # m1=1.48 Msun, m2=1.265 Msun, m2/m1=0.85, Mtot=2.74 Msun, eta=m1*m2/(m1+m2)**2\n",
    "    'chi1z': 0,\n",
    "    'chi2z': 0,\n",
    "    'DL':    40, # MPc\n",
    "    'tc':    0, # not quoted\n",
    "    'phic':  0,\n",
    "#     'iota':  PI/4, # 1000 random instances of these, measured: 55deg\n",
    "#     'ra':    PI/4, # 1000 random instances of these\n",
    "#     'dec':   PI/4, # 1000 random instances of these\n",
    "    'psi':   PI/4, # not quoted, to-do: check effect\n",
    "    'gmst0': 0, # not quoted but doesn't matter?\n",
    "    'lam_t': 800, # combined dimensionless tidal deformability\n",
    "    'delta_lam_t': 0 # not quoted, but approximating as zero because distributed around zero (check)\n",
    "}\n",
    "\n",
    "# assign with respect to which parameters to take derivatives, for the FIM, all 12 but not delta_lam_t (or gmst0)\n",
    "deriv_symbs_string = 'Mc eta chi1z chi2z DL tc phic iota ra dec psi lam_t'\n",
    "\n",
    "# assign which parameters to convert to log or cos versions for differentiation\n",
    "conv_log = ('Mc', 'DL', 'lam_t')\n",
    "conv_cos = ('iota', 'dec')\n",
    "\n",
    "# choose whether to take Earth's rotation into account\n",
    "use_rot = 0\n",
    "# whether to calculate snr, errors, sky area for just the network and not the individual detectors\n",
    "only_net = 1\n",
    "\n",
    "# create lambdified derivatives for speed\n",
    "generate_symbolic_derivatives(wf_model_name, wf_other_var_dic, deriv_symbs_string, locs, use_rot)\n",
    "\n",
    "# starting with just 10 instances, scale up to 1000 later\n",
    "num_instances = 1000 # 1000 is O(10 min) with numerical derivatives but is O(1 min) with symbolic derivatives\n",
    "file_tag = f'{num_instances}instances_{net_label_styler(net.label)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles are sampled to avoid clumping at poles\n",
    "iota_ra_dec_randoms = np.transpose(injections.angle_sampler(num_instances, np.random.randint(100))[:-1])\n",
    "\n",
    "def calculate_snr_errs_skyarea(iota_ra_dec):\n",
    "    \"\"\"given an array of iota, ra, dec; return an array of the integrate snr, Mc and DL errors, and 90% sky area\"\"\"\n",
    "    iota, ra, dec = iota_ra_dec\n",
    "    inj_params = dict(**base_measured_params, iota=iota, ra=ra, dec=dec)\n",
    "\n",
    "    # copy network to avoid parallel operations conflicting, is this an issue when Pool() makes separate instances?\n",
    "    net_copy = deepcopy(net)\n",
    "\n",
    "    net_copy.set_net_vars(\n",
    "        f=f, inj_params=inj_params,\n",
    "        deriv_symbs_string=deriv_symbs_string,\n",
    "        conv_cos=conv_cos, conv_log=conv_log,\n",
    "        use_rot=use_rot\n",
    "    )\n",
    "\n",
    "    basic_network_benchmarking(net_copy, numerical_over_symbolic_derivs=False, only_net=only_net)\n",
    "\n",
    "    if net_copy.wc_fisher: # i.e. net.cond_num < 1e15:\n",
    "        # net_copy is automatically deleted once out of scope\n",
    "        return net_copy.snr, net_copy.errs['log_Mc'], net_copy.errs['log_DL'], net_copy.errs['sky_area_90']\n",
    "    else:\n",
    "        # try again with different random values\n",
    "        # to-do: add counter to quantify rate of occurance; seems to be v common with CE only, why?\n",
    "        #print(f'{net_copy.cond_num:.3g} is ill-conditioned, try again')\n",
    "        #return calculate_snr_errs_skyarea(np.transpose(injections.angle_sampler(1, np.random.randint(100))[:-1]))\n",
    "        # alternative to guarantee halting \n",
    "        return np.full(4, np.nan)\n",
    "\n",
    "# array to store integrated SNR, 1sigma error estimates (for Mc and DL), and 90% credible sky area\n",
    "# must be careful with parallelising that the network is not used simultaneously\n",
    "# keeping one cpu free to use laptop\n",
    "results_snr_errs_skyarea = np.array(p_umap(calculate_snr_errs_skyarea, iota_ra_dec_randoms, num_cpus=3))\n",
    "\n",
    "# save results\n",
    "np.save(f'data_snr_errs_skyarea/results_snr_errs_skyarea_{file_tag}.npy', results_snr_errs_skyarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results\n",
    "results_snr_errs_skyarea = np.load(f'data_snr_errs_skyarea/results_snr_errs_skyarea_{file_tag}.npy')\n",
    "\n",
    "# filter out NaNs\n",
    "results_snr_errs_skyarea = without_rows_w_nan(results_snr_errs_skyarea)\n",
    "\n",
    "if len(results_snr_errs_skyarea) == 0:\n",
    "    print('All values are NaN, FIM is ill-conditioned.')\n",
    "else:\n",
    "    print('Some values are not NaN.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9384d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measured values\n",
    "# given Appendix E: Asymmetric Systematic Uncertainties, estimating the st.dev. from asymm errs depends on your model\n",
    "# in the Gaussian case, just average the upper and lower errors that correspond to 68% of the data\n",
    "# given a 90% credibility interval (x-xlower,x+xupper), the st.dev. is approximated by 1/1.64*1/2(xlower+xupper)\n",
    "meas_snr = 32.4\n",
    "# too high eyeballing wrt Borhanian 2021?\n",
    "meas_Mc_rel_err = 1/1.64*1/2*(0.004+0.002)/1.188 # 1.188+0.004-0.002, range for 90% credibility\n",
    "# too low eyeballing wrt Borhanian 2021?\n",
    "meas_LD_rel_err = 1/1.64*1/2*(8+14)/40 # 40+8âˆ’14\n",
    "meas_sky_area = 28\n",
    "meas_vals = meas_snr, meas_Mc_rel_err, meas_LD_rel_err, meas_sky_area\n",
    "\n",
    "# plotting\n",
    "# comparing symmetricised relative errors rather than 90% credible bounds\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, axs = plt.subplots(1, 4, figsize=(18, 2), sharey=True, gridspec_kw={'wspace':0.05, 'hspace':0})\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    data = results_snr_errs_skyarea[:,i]\n",
    "    ax.hist(data, histtype='step', facecolor='b', label='tf2_tidal',\n",
    "            bins=np.geomspace(data.min(), data.max(), 50))\n",
    "    ax.axvline(meas_vals[i], color='grey')\n",
    "    ax.set_xscale('log')\n",
    "    # NB: when there's no major tick, the axis has no reference value\n",
    "    ax.xaxis.set_minor_locator(plt.LogLocator(base=10.0, subs=0.1*np.arange(1, 10), numticks=10))\n",
    "    ax.xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "\n",
    "snr_xlim = axs[0].get_xlim()\n",
    "for snr_threshold in SNR_THRESHOLD_LO, SNR_THRESHOLD_HI:\n",
    "    efficiency = np.mean(results_snr_errs_skyarea[:,0] > snr_threshold)\n",
    "    print(f\"efficiency of network is {efficiency:.1%} wrt SNR threshold {snr_threshold}\")\n",
    "axs[0].axvspan(snr_xlim[0], SNR_THRESHOLD_LO, alpha=0.5, color='lightgrey')\n",
    "axs[0].axvspan(snr_xlim[0], SNR_THRESHOLD_HI, alpha=0.25, color='lightgrey')\n",
    "axs[0].set_xlim(snr_xlim)\n",
    "\n",
    "axs[0].set_ylabel('GW170817\\ncount')\n",
    "axs[0].set_xlabel(r'integrated SNR, $\\rho$')\n",
    "# error in log(X) is the fractional error in X (i.e. (error in X)/X) by chain rule \n",
    "axs[1].set_xlabel(r'chirp mass, $\\Delta\\mathcal{M}/\\mathcal{M}$')\n",
    "axs[2].set_xlabel(r'luminosity distance, $\\Delta D_L/D_L$')\n",
    "axs[3].set_xlabel(r'sky area, $\\Omega$ / $\\mathrm{deg}^2$')\n",
    "axs[0].legend()\n",
    "\n",
    "fig.align_labels()\n",
    "fig.savefig(f'plots/GW170817_histograms_{file_tag}.pdf', bbox_inches='tight')\n",
    "plt.show(fig)\n",
    "plt.close(fig)\n",
    "# results for HLV disagree with Borhanian2021: sharpness of first twos' fall-offs, centre of snr distribution, measured Mc and DL, extent of sky area curve\n",
    "# however, with a difference 1000 instances, the results change --- so maybe just a sampling issue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
