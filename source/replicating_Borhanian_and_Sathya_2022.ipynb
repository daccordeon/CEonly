{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "James Gardner, 2022 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to analyse science case/s for CE only:\n",
    "\n",
    "CE-N 40km with CE-S 40km or 20km\n",
    "\n",
    "if done, then look at CE-S with one ET detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking import *\n",
    "from gwbench.basic_relations import f_isco_Msolar\n",
    "\n",
    "from scipy.stats import gmean\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.integrate import quad\n",
    "from astropy.cosmology import Planck18\n",
    "from p_tqdm import p_map\n",
    "\n",
    "# suppress warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "def save_benchmark_from_generated_injections(net, redshift_bins, num_injs,\n",
    "                                             mass_dict, spin_dict, redshifted,\n",
    "                                             base_params, deriv_symbs_string, coeff_fisco,\n",
    "                                             conv_cos, conv_log, use_rot, only_net,\n",
    "                                             numerical_over_symbolic_derivs, numerical_deriv_settings,\n",
    "                                             file_tag):\n",
    "    \"\"\"given network and variables, generate injections, benchmark, \n",
    "    and save results (snr, errors in logM logDL eta iota, sky area) as .npy\n",
    "    to-do: tidy up number of arguments\"\"\"\n",
    "    # injection and benchmarking\n",
    "    # concatenate injection data from different bins\n",
    "    inj_data = np.empty((len(redshift_bins)*num_injs, 14))\n",
    "    for i, (zmin, zmax, seed) in enumerate(redshift_bins):\n",
    "        cosmo_dict = dict(sampler='uniform', zmin=zmin, zmax=zmax)\n",
    "        # transposed array to get [[Mc0, eta0, ..., z0], [Mc1, eta1, ..., z1], ...]\n",
    "        # [Mc, eta, chi1x, chi1y, chi1z, chi2x, chi2y, chi2z, DL, iota, ra, dec, psi, z]    \n",
    "        inj_data[i*num_injs:(i+1)*num_injs] = np.array(injections.injections_CBC_params_redshift(cosmo_dict, mass_dict, spin_dict, redshifted, num_injs=num_injs, seed=seed)).transpose()\n",
    "\n",
    "    def calculate_benchmark_from_injection(inj):\n",
    "        \"\"\"given a 14-array of [Mc, eta, chi1x, chi1y, chi1z, chi2x, chi2y, chi2z, DL, iota, ra, dec, psi, z],\n",
    "        returns a 7-tuple of the\n",
    "        * redshift z,\n",
    "        * integrated snr,\n",
    "        * fractional Mc and DL and absolute eta and iota errors,\n",
    "        * 90% sky area.\n",
    "        sigma_log(Mc) = sigma_Mc/Mc is fractional error in Mc and similarly for DL, sigma_eta is absolute,\n",
    "        while |sigma_cos(iota)| = |sigma_iota*sin(iota)| --> error in iota requires rescaling from output\"\"\"\n",
    "        varied_keys = ['Mc', 'eta', 'chi1x', 'chi1y', 'chi1z', 'chi2x', 'chi2y', 'chi2z', 'DL', 'iota', 'ra', 'dec', 'psi', 'z']\n",
    "        varied_params = dict(zip(varied_keys, inj))\n",
    "        z = varied_params.pop('z')\n",
    "        Mc, eta, iota = varied_params['Mc'], varied_params['eta'], varied_params['iota']\n",
    "\n",
    "        Mtot = Mc/eta**0.6\n",
    "        #fisco = (6**1.5*PI*Mtot)**-1 # missing some number of Msun, c=1, G=1 factors\n",
    "        fisco = f_isco_Msolar(Mtot) #4.4/Mtot*1e3 # Hz # from https://arxiv.org/pdf/2011.05145.pdf\n",
    "        fmin, fmax, df = 5., float(min(coeff_fisco*fisco, 1024)), 10 # df=1/16 (fine) \n",
    "        f = np.arange(fmin, fmax, df)\n",
    "\n",
    "        # net_copy is automatically deleted once out of scope (is copying necessary with Pool()?)\n",
    "        net_copy = deepcopy(net)\n",
    "        inj_params = dict(**base_params, **varied_params)\n",
    "        net_copy.set_net_vars(f=f, inj_params=inj_params, deriv_symbs_string=deriv_symbs_string,\n",
    "                              conv_cos=conv_cos, conv_log=conv_log, use_rot=use_rot)\n",
    "\n",
    "        basic_network_benchmarking(net_copy, numerical_over_symbolic_derivs=numerical_over_symbolic_derivs, only_net=only_net,\n",
    "                                   numerical_deriv_settings=numerical_deriv_settings, hide_prints=True)\n",
    "\n",
    "        if net_copy.wc_fisher:\n",
    "            # convert sigma_cos(iota) into sigma_iota\n",
    "            abs_err_iota = abs(net_copy.errs['cos_iota']/np.sin(iota))\n",
    "            return (z, net_copy.snr, net_copy.errs['log_Mc'], net_copy.errs['log_DL'], net_copy.errs['eta'],\n",
    "                    abs_err_iota, net_copy.errs['sky_area_90'])\n",
    "        else:\n",
    "            # to-do: check if CE only is still ill-conditioned\n",
    "            return (z, *np.full(6, np.nan))\n",
    "\n",
    "    # calculate results: z, snr, errs (logMc, logDL, eta, iota), sky area\n",
    "    # p_umap is unordered in redshift for greater speed (check)\n",
    "    results = np.array(p_umap(calculate_benchmark_from_injection, inj_data, num_cpus=os.cpu_count()-1))\n",
    "    # filter out NaNs\n",
    "    results = without_rows_w_nan(results)\n",
    "    if len(results) == 0:\n",
    "        raise ValueError('All calculated values are NaN, FIM is ill-conditioned.')\n",
    "    np.save(f'data_B&S2022_replication/results_{file_tag}.npy', results)\n",
    "\n",
    "def plot_snr_eff_detrate_vs_redshift(results, zavg_efflo_effhi,\n",
    "                                    sigmoid_3parameter, det_eff_fits, det_rate_limit, det_rate,\n",
    "                                    zmin_plot, zmax_plot,\n",
    "                                    file_tag, human_file_tag, show_fig=True,\n",
    "                                    print_progress=True, p0s=None):\n",
    "    \"\"\"plotting to replicate Fig 2 in B&S2022\n",
    "    to-do: tidy up number of arguments\"\"\"    \n",
    "    colours = 'darkred', 'red'\n",
    "    zaxis_plot = np.geomspace(zmin_plot, zmax_plot, 100)\n",
    "\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, axs = plt.subplots(3, 1, sharex=True, figsize=(6, 12), gridspec_kw={'wspace':0, 'hspace':0.05})\n",
    "\n",
    "    # SNR vs redshift\n",
    "    # use integrated SNR rho from standard benchmarking, not sure if B&S2022 use matched filter\n",
    "    axs[0].loglog(results[:,0], results[:,1], '.')\n",
    "    axs[0].axhspan(0, SNR_THRESHOLD_LO, alpha=0.5, color='lightgrey')\n",
    "    axs[0].axhspan(0, SNR_THRESHOLD_HI, alpha=0.25, color='lightgrey')\n",
    "    axs[0].set_ylabel(r'integrated SNR, $\\rho$')\n",
    "    axs[0].set_title(human_file_tag, fontsize=14)\n",
    "\n",
    "    # efficiency vs redshift\n",
    "    axs[1].axhline(0, color='grey', linewidth=0.5)\n",
    "    axs[1].axhline(1, color='grey', linewidth=0.5)\n",
    "    axs[1].plot(zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,1], 'o', color=colours[0], label=fr'$\\rho$ > {SNR_THRESHOLD_LO}')\n",
    "    axs[1].plot(zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,2], 's', color=colours[1], label=fr'$\\rho$ > {SNR_THRESHOLD_HI}')\n",
    "    axs[1].semilogx(zaxis_plot, det_eff_fits[0](zaxis_plot), color=colours[0], label='optimal fit')\n",
    "    # fit using parameters p0s from B&S2022\n",
    "    if p0s is not None:\n",
    "        axs[1].semilogx(zaxis_plot, list(p_map(lambda z : sigmoid_3parameter(z, *p0s[0]),   zaxis_plot)), color=colours[0], linestyle='dotted', label='fit from B&S2022') \n",
    "        axs[1].semilogx(zaxis_plot, list(p_map(lambda z : sigmoid_3parameter(z, *p0s[1]),   zaxis_plot)), color=colours[1], linestyle='dotted')\n",
    "    axs[1].semilogx(zaxis_plot, det_eff_fits[1](zaxis_plot), color=colours[1])\n",
    "    axs[1].legend()\n",
    "    axs[1].set_ylim((0-0.05, 1+0.05))\n",
    "    axs[1].set_ylabel(r'detection efficiency, $\\varepsilon$')\n",
    "    fig.align_ylabels()\n",
    "\n",
    "    # detection rate vs redshift\n",
    "    # merger rate depends on star formation rate and the delay between formation and merger\n",
    "    axs[2].loglog(zaxis_plot, list(p_map(det_rate_limit, zaxis_plot)), color='black', linewidth=1)\n",
    "    axs[2].loglog(zaxis_plot, list(p_map(lambda z : det_rate(z, snr_threshold=10), zaxis_plot)), color=colours[0])\n",
    "    axs[2].loglog(zaxis_plot, list(p_map(lambda z : det_rate(z, snr_threshold=100), zaxis_plot)), color=colours[1])\n",
    "    if print_progress: print('Detection rate calculated.')\n",
    "    # axs[2].set_ylabel(r'detection rate, $D_R$ / $\\mathrm{yr}^{-1}$')\n",
    "    axs[2].set_ylabel('detection rate, D_R / [T^-1]\\nscale is wrong, why?')\n",
    "\n",
    "    axs[-1].set_xscale('log')\n",
    "    axs[-1].set_xlim((zmin_plot, zmax_plot))\n",
    "    axs[-1].xaxis.set_minor_locator(plt.LogLocator(base=10.0, subs=0.1*np.arange(1, 10), numticks=10))\n",
    "    axs[-1].xaxis.set_minor_formatter(plt.NullFormatter())\n",
    "    axs[-1].set_xlabel('redshift, z')\n",
    "\n",
    "    fig.savefig(f'plots/snr_eff_rate_vs_redshift_{file_tag}.pdf', bbox_inches='tight')\n",
    "    if show_fig:\n",
    "        plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicating Borhanian and Sathya 2022 injections and detection rates, then for CE only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_rate_for_network_and_waveform(network_spec, wf_model_name, wf_other_var_dic, num_injs,\n",
    "                                            show_fig=True, print_progress=True):\n",
    "    \"\"\"initialises network, benchmarks, calculates detection rate, plots\"\"\"\n",
    "    # initialisation\n",
    "    locs = [x.split('_')[-1] for x in network_spec]\n",
    "    net = network.Network(network_spec)\n",
    "    net.set_wf_vars(wf_model_name=wf_model_name, wf_other_var_dic=wf_other_var_dic)\n",
    "    \n",
    "    # --- BNS ---\n",
    "    # injection settings - source\n",
    "    mass_dict = dict(dist='gaussian', mean=1.35, sigma=0.15, mmin=1, mmax=2)\n",
    "    spin_dict = dict(geom='cartesian', dim=1, chi_lo=-0.05, chi_hi=0.05)\n",
    "    # zmin, zmax, seed (use same seeds to replicate results)\n",
    "    # typo in AppA that starts at 0 rather than 0.02 (in main text)?\n",
    "    redshift_bins = ((0.02, 0.5, 7669), (0.5, 1, 3103), (1, 2, 4431), (2, 4, 5526), (4, 10, 7035), (10, 50, 2785))\n",
    "    coeff_fisco = 4 # fmax = 4*fisco for BNS, 8*fisco for BBH\n",
    "\n",
    "    base_params = {\n",
    "        'tc':    0,\n",
    "        'phic':  0,\n",
    "        'gmst0': 0, # assume zero given B2021\n",
    "        # to-do: find correct tidal parameters\n",
    "        'lam_t': 800, # combined dimensionless tidal deformability, 800 for GW170817, to-do: what did B&S2022 use?\n",
    "        'delta_lam_t': 0, # assuming zero but can be calculated if m1, m2, Love number, and EoS (i.e. radii) known\n",
    "    }\n",
    "\n",
    "    # derivative settings\n",
    "    # assign with respect to which parameters to take derivatives for the FIM\n",
    "    deriv_symbs_string = 'Mc eta DL tc phic iota ra dec psi'\n",
    "    # assign which parameters to convert to log or cos versions for differentiation\n",
    "    conv_cos = ('dec', 'iota')\n",
    "    conv_log = ('Mc', 'DL', 'lam_t')\n",
    "\n",
    "    # network settings: whether to include Earth's rotation and individual detector calculations\n",
    "    use_rot = 1\n",
    "    only_net = 1\n",
    "\n",
    "    # injection settings - other: number of injections per redshift bin (over 6 bins)\n",
    "    redshifted = 1 # whether sample masses already redshifted wrt z\n",
    "    if wf_other_var_dic is not None:\n",
    "        file_tag = f'NET_{net.label}_WF_{wf_model_name}_{wf_other_var_dic[\"approximant\"]}_NUM-INJS_{num_injs}'\n",
    "        human_file_tag = f'network: {net.label.replace(\"..\", \", \")}\\nwaveform: {wf_model_name} with {wf_other_var_dic[\"approximant\"]}\\nnumber of injections per bin: {num_injs}'\n",
    "    else:\n",
    "        file_tag = f'NET_{net.label}_WF_{wf_model_name}_NUM-INJS_{num_injs}'\n",
    "        human_file_tag = f'network: {net.label.replace(\"..\", \", \")}\\nwaveform: {wf_model_name}\\nnumber of injections per bin: {num_injs}'    \n",
    "    \n",
    "    if print_progress: print('Network initialised.')\n",
    "    # use symbolic derivatives if able\n",
    "    if (wf_model_name == 'tf2') | (wf_model_name == 'tf2_tidal'):\n",
    "        numerical_over_symbolic_derivs = False    \n",
    "        generate_symbolic_derivatives(wf_model_name, wf_other_var_dic, deriv_symbs_string, locs, use_rot)\n",
    "        numerical_deriv_settings = None\n",
    "    else:\n",
    "        numerical_over_symbolic_derivs = True\n",
    "        numerical_deriv_settings = dict(step=1e-9, method='central', order=2, n=1) # default\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # generate results or skip if previously generated successfully (i.e. not ill-conditioned)\n",
    "    if not os.path.isfile(f'data_B&S2022_replication/results_{file_tag}.npy'):\n",
    "        save_benchmark_from_generated_injections(net, redshift_bins, num_injs,\n",
    "                                                mass_dict, spin_dict, redshifted,\n",
    "                                                base_params, deriv_symbs_string, coeff_fisco,\n",
    "                                                conv_cos, conv_log, use_rot, only_net,\n",
    "                                                numerical_over_symbolic_derivs, numerical_deriv_settings,\n",
    "                                                file_tag)\n",
    "\n",
    "    results = np.load(f'data_B&S2022_replication/results_{file_tag}.npy')\n",
    "    if print_progress: print('Results found/loaded.')\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # calculting efficiency and detection rate for plotting\n",
    "    # count efficiency over sources in (z, z+Delta_z)\n",
    "    zmin_plot, zmax_plot, num_zbins_fine = 1e-2, 50, 40 # eyeballing 40 bins from Fig 2\n",
    "    redshift_bins_fine = list(zip(np.geomspace(zmin_plot, zmax_plot, num_zbins_fine)[:-1],\n",
    "                                  np.geomspace(zmin_plot, zmax_plot, num_zbins_fine)[1:])) # redshift_bins are too wide\n",
    "    zavg_efflo_effhi = np.empty((len(redshift_bins_fine), 3))\n",
    "    for i, (zmin, zmax) in enumerate(redshift_bins_fine):\n",
    "        z_snr_in_bin = results[:,0:2][np.logical_and(zmin < results[:,0], results[:,0] < zmax)]\n",
    "        if len(z_snr_in_bin) == 0:\n",
    "            zavg_efflo_effhi[i] = [np.nan, np.nan, np.nan]\n",
    "        else:\n",
    "            zavg_efflo_effhi[i,0] = gmean(z_snr_in_bin[:,0]) # geometric mean, just using zmax is cleaner but less accurate\n",
    "            zavg_efflo_effhi[i,1] = np.mean(z_snr_in_bin[:,1] > SNR_THRESHOLD_LO)\n",
    "            zavg_efflo_effhi[i,2] = np.mean(z_snr_in_bin[:,1] > SNR_THRESHOLD_HI)\n",
    "    zavg_efflo_effhi = without_rows_w_nan(zavg_efflo_effhi)    \n",
    "\n",
    "    # fit three-parameter sigmoids to efficiency curves vs redshift\n",
    "    sigmoid_3parameter = lambda z, a, b, c : ((1+b)/(1+b*np.exp(a*z)))**c\n",
    "    # from Table 9\n",
    "    p0s = [[62.08, 0.00584, 0.3341], [607.7, 0.006674, 0.3529]] # for 'A+_H..A+_L..V+_V..K+_K..A+_I'\n",
    "    if net.label == 'A+_H..A+_L..V+_V..K+_K..A+_I':\n",
    "        fit_p0s = [[62.08, 0.00584, 0.3341], [607.7, 0.006674, 0.3529]] # threshold 10 then 100\n",
    "    else:\n",
    "        fit_p0s = None\n",
    "    # use p0=(ai,bi,ci) or bounds=([a0,a1],[b0,b1],[c0,c1])\n",
    "    popts, pcovs = zip(curve_fit(sigmoid_3parameter, zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,1], method='dogbox', p0=p0s[0]),\n",
    "                       curve_fit(sigmoid_3parameter, zavg_efflo_effhi[:,0], zavg_efflo_effhi[:,2], method='dogbox', p0=p0s[1]))\n",
    "    perrs = [np.sqrt(np.diag(pcov)) for pcov in pcovs]\n",
    "    # lambdas in list comprehension are unintuitive, be explicit unless confident, see:\n",
    "    # https://stackoverflow.com/questions/6076270/lambda-function-in-list-comprehensions\n",
    "    # det_eff_fits = [(lambda z : sigmoid_3parameter(z, *popt)) for popt in popts]\n",
    "    det_eff_fits = [(lambda z : sigmoid_3parameter(z, *popts[0])), (lambda z : sigmoid_3parameter(z, *popts[1]))]\n",
    "    # print(f'input {p0}\\noptimal {list(popt)}\\nerrors {perr}')\n",
    "\n",
    "    # detection efficiency, interpolate from sigmoid fit\n",
    "    def det_eff(z, snr_threshold):\n",
    "        if snr_threshold == 10:\n",
    "            return det_eff_fits[0](z)\n",
    "        elif snr_threshold == 100:\n",
    "            return det_eff_fits[1](z)\n",
    "        else:\n",
    "            # to-do: add this feature\n",
    "            raise ValueError(\"SNR thresholds other than 10 or 100 are not yet supported\") \n",
    "\n",
    "    # to-do: fix merger rate so that the plot reaches beyond 1e5 detections per year, maybe a units issue?\n",
    "    #merger_rate = lambda z: injections.bns_md_merger_rate(z) # too low (1e1) but below is too large (1e13)\n",
    "    # don't know if injections.bns_md_merger_rate(z) is R(z) or \\dot{n}(z) (merger rate density)\n",
    "    # bns_md_merger_rate_uniform_comoving_volume_redshift_inversion_sampler suggests the latter\n",
    "    differential_comoving_volume = lambda z : 4.*PI*Planck18.differential_comoving_volume(z).value # in Mpc^3\n",
    "    merger_rate = lambda z: injections.bns_md_merger_rate(z)*differential_comoving_volume(z) # now in yr^-1? what is bns_md..._rate in?\n",
    "    # want merger rate density in Mpc^-3 yr^-1, not just 1e-9 difference (e.g. Mpc^3 to Gpc^3) or c\n",
    "\n",
    "    # i.e. \"merger rate\" in Fig 2, not R(z) but int R(z)/(1+z), i.e. if perfect efficiency, quad returns (value, error)\n",
    "    det_rate_limit = lambda z0 : quad(lambda z : merger_rate(z)/(1+z), 0, z0)[0]\n",
    "    # detection rate\n",
    "    det_rate = lambda z0, snr_threshold : quad(lambda z : det_eff(z, snr_threshold)*merger_rate(z)/(1+z), 0, z0)[0]\n",
    "    if print_progress: print('Detection rate defined.')\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # plotting\n",
    "    plot_snr_eff_detrate_vs_redshift(results, zavg_efflo_effhi,\n",
    "                                    sigmoid_3parameter, det_eff_fits, det_rate_limit, det_rate,\n",
    "                                    zmin_plot, zmax_plot,\n",
    "                                    file_tag, human_file_tag, show_fig=show_fig,\n",
    "                                    print_progress=print_progress, p0s=fit_p0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure: network, injection loop (inj, benchmark, save data), plot snr histogram, ...\n",
    "# ... calculate efficiency, calculate detection rate\n",
    "\n",
    "# try for this network, then CE only (refer to App E for CE discussion), compare to other five in Section 2a?\n",
    "# --- HLVKI+ ---\n",
    "network_spec = ['A+_H', 'A+_L', 'V+_V', 'K+_K', 'A+_I']\n",
    "# --- VK+HLIv ---\n",
    "# network_spec = ['V+_V', 'K+_K', 'Voyager-CBO_H', 'Voyager-CBO_L', 'Voyager-CBO_I']\n",
    "# --- HLKI+E ---\n",
    "# network_spec = ['A+_H', 'A+_L', 'K+_K', 'A+_I', 'ET_ET1'] # _E incorrect\n",
    "# --- VKI+C ---\n",
    "# network_spec = ['V+_V', 'K+_K', 'A+_I', 'CE1-40-CBO_C']\n",
    "# --- KI+EC ---\n",
    "# network_spec = ['K+_K', 'A+_I', 'ET_ET1', 'CE1-40-CBO_C']\n",
    "# --- ECS ---\n",
    "# network_spec = ['ET_ET1', 'CE1-40-CBO_C', 'CE1-40-CBO_S']\n",
    "# !--- CE only ---!\n",
    "# network_spec = ['CE1-40-CBO_C', 'CE1-40-CBO_S'] # --> FIM still ill-conditioned\n",
    "# network_spec = ['CE2-40-CBO_C', 'CE2-40-CBO_S']\n",
    "# network_spec = ['CE1-40-CBO_C', 'CE1-20-PMO_S']\n",
    "# network_spec = ['CE2-40-CBO_C', 'CE2-20-PMO_S']\n",
    "\n",
    "# --- BNS ---\n",
    "# waveform, LAL list: https://lscsoft.docs.ligo.org/lalsuite/lalsimulation/group___l_a_l_sim_inspiral__h.html\n",
    "wf_model_name, wf_other_var_dic = 'lal_bns', dict(approximant='IMRPhenomD_NRTidalv2') # for tidal, see https://arxiv.org/abs/1905.06011\n",
    "# to-do: fix \"TypeError: hfpc() missing 2 required positional arguments: 'lam_t' and 'delta_lam_t'\"\n",
    "# --> calculate tidal parameters from sampled m1, m2 in injections.py? requires Love number and radii (i.e. choose an EoS)\n",
    "# wf_model_name, wf_other_var_dic = 'tf2', None # to-do: stop using this once tidal params found\n",
    "# wf_model_name, wf_other_var_dic = 'tf2_tidal', None\n",
    "\n",
    "num_injs = 10 # start with 10, then build to 1e6 (how did they compute 1e6 with numerical derivs?)\n",
    "\n",
    "detection_rate_for_network_and_waveform(network_spec, wf_model_name, wf_other_var_dic, num_injs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: fix merger rate units from 1e13 to just over 1e5 detections maximum per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: increase sampling below 4e-2, but App A uses (0, 0.5, seed)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: tidy up refactoring, reduce total number of arguments with unpacking?\n",
    "# to-do: CE only is still ill-conditioned, why?\n",
    "# to-do: make combined plot of different networks a la Fig 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: study BBH science case as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In fact, we see that the three generations (A+, Voyager, and NG) are qualitatively different\n",
    "with respect to every metric used in this study.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
